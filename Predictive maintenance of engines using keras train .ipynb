{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('PM_train.txt',sep=' ',header=None).drop([26,27],axis=1)\n",
    "column_names=['id','cycle','settings1','settings2','settings3','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21']\n",
    "traindata.columns=column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>settings1</th>\n",
       "      <th>settings2</th>\n",
       "      <th>settings3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>ttf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.10</td>\n",
       "      <td>1584.47</td>\n",
       "      <td>1398.37</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8132.85</td>\n",
       "      <td>8.4108</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.98</td>\n",
       "      <td>23.3669</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.48</td>\n",
       "      <td>1592.32</td>\n",
       "      <td>1397.77</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8132.32</td>\n",
       "      <td>8.3974</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.10</td>\n",
       "      <td>23.3774</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.56</td>\n",
       "      <td>1582.96</td>\n",
       "      <td>1400.97</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8131.07</td>\n",
       "      <td>8.4076</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.97</td>\n",
       "      <td>23.3106</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.12</td>\n",
       "      <td>1590.98</td>\n",
       "      <td>1394.80</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8125.69</td>\n",
       "      <td>8.3728</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.05</td>\n",
       "      <td>23.4066</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1591.24</td>\n",
       "      <td>1400.46</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8129.38</td>\n",
       "      <td>8.4286</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.4694</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.28</td>\n",
       "      <td>1581.75</td>\n",
       "      <td>1400.64</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>8140.58</td>\n",
       "      <td>8.4340</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.94</td>\n",
       "      <td>23.4787</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.06</td>\n",
       "      <td>1583.41</td>\n",
       "      <td>1400.15</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8134.25</td>\n",
       "      <td>8.3938</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.3660</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.07</td>\n",
       "      <td>1582.19</td>\n",
       "      <td>1400.83</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8128.10</td>\n",
       "      <td>8.4152</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.93</td>\n",
       "      <td>23.2757</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1592.95</td>\n",
       "      <td>1399.16</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8134.43</td>\n",
       "      <td>8.3964</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.18</td>\n",
       "      <td>23.3826</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.43</td>\n",
       "      <td>1583.82</td>\n",
       "      <td>1402.13</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8127.56</td>\n",
       "      <td>8.4199</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.3500</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.13</td>\n",
       "      <td>1587.98</td>\n",
       "      <td>1404.50</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8136.11</td>\n",
       "      <td>8.3936</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.97</td>\n",
       "      <td>23.4550</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.58</td>\n",
       "      <td>1584.96</td>\n",
       "      <td>1399.95</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8137.27</td>\n",
       "      <td>8.4542</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.81</td>\n",
       "      <td>23.3319</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.62</td>\n",
       "      <td>1591.04</td>\n",
       "      <td>1396.12</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8132.73</td>\n",
       "      <td>8.4028</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.89</td>\n",
       "      <td>23.3987</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.79</td>\n",
       "      <td>1587.56</td>\n",
       "      <td>1400.35</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8129.13</td>\n",
       "      <td>8.4321</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.80</td>\n",
       "      <td>23.3464</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.04</td>\n",
       "      <td>1581.11</td>\n",
       "      <td>1405.23</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8129.71</td>\n",
       "      <td>8.4210</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.03</td>\n",
       "      <td>23.4220</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1586.07</td>\n",
       "      <td>1398.13</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8134.02</td>\n",
       "      <td>8.4049</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.09</td>\n",
       "      <td>23.3101</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.77</td>\n",
       "      <td>1592.93</td>\n",
       "      <td>1400.57</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8130.41</td>\n",
       "      <td>8.4034</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.92</td>\n",
       "      <td>23.3792</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.14</td>\n",
       "      <td>1588.19</td>\n",
       "      <td>1394.75</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8127.90</td>\n",
       "      <td>8.4240</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.94</td>\n",
       "      <td>23.4562</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.38</td>\n",
       "      <td>1590.83</td>\n",
       "      <td>1398.81</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.88</td>\n",
       "      <td>8.3891</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3696</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.77</td>\n",
       "      <td>1594.10</td>\n",
       "      <td>1399.39</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8136.61</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.4288</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.16</td>\n",
       "      <td>1589.08</td>\n",
       "      <td>1396.07</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8131.15</td>\n",
       "      <td>8.4260</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.4149</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1590.47</td>\n",
       "      <td>1401.84</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>8134.60</td>\n",
       "      <td>8.4046</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4472</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.84</td>\n",
       "      <td>1399.13</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8127.30</td>\n",
       "      <td>8.4323</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.01</td>\n",
       "      <td>23.2841</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.91</td>\n",
       "      <td>1584.83</td>\n",
       "      <td>1400.99</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8133.06</td>\n",
       "      <td>8.4189</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.93</td>\n",
       "      <td>23.3597</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.20</td>\n",
       "      <td>1593.52</td>\n",
       "      <td>1396.08</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8137.86</td>\n",
       "      <td>8.4065</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.05</td>\n",
       "      <td>23.4110</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20601</th>\n",
       "      <td>100</td>\n",
       "      <td>171</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.05</td>\n",
       "      <td>1593.56</td>\n",
       "      <td>1420.48</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.18</td>\n",
       "      <td>8144.03</td>\n",
       "      <td>8.5085</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.81</td>\n",
       "      <td>23.1513</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20602</th>\n",
       "      <td>100</td>\n",
       "      <td>172</td>\n",
       "      <td>-0.0037</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.97</td>\n",
       "      <td>1602.35</td>\n",
       "      <td>1424.93</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.19</td>\n",
       "      <td>8142.08</td>\n",
       "      <td>8.4970</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>23.1922</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20603</th>\n",
       "      <td>100</td>\n",
       "      <td>173</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.40</td>\n",
       "      <td>1595.53</td>\n",
       "      <td>1418.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.17</td>\n",
       "      <td>8143.13</td>\n",
       "      <td>8.4856</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.42</td>\n",
       "      <td>23.1793</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20604</th>\n",
       "      <td>100</td>\n",
       "      <td>174</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.91</td>\n",
       "      <td>1602.24</td>\n",
       "      <td>1425.52</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.15</td>\n",
       "      <td>8143.61</td>\n",
       "      <td>8.4990</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.80</td>\n",
       "      <td>23.1784</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20605</th>\n",
       "      <td>100</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.85</td>\n",
       "      <td>1602.03</td>\n",
       "      <td>1416.24</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.17</td>\n",
       "      <td>8140.88</td>\n",
       "      <td>8.4851</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.54</td>\n",
       "      <td>23.0713</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20606</th>\n",
       "      <td>100</td>\n",
       "      <td>176</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.33</td>\n",
       "      <td>1601.44</td>\n",
       "      <td>1421.40</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.19</td>\n",
       "      <td>8139.27</td>\n",
       "      <td>8.4405</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.46</td>\n",
       "      <td>23.1020</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20607</th>\n",
       "      <td>100</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.34</td>\n",
       "      <td>1593.22</td>\n",
       "      <td>1418.91</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.18</td>\n",
       "      <td>8142.95</td>\n",
       "      <td>8.5133</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.60</td>\n",
       "      <td>23.0352</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20608</th>\n",
       "      <td>100</td>\n",
       "      <td>178</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.98</td>\n",
       "      <td>1594.80</td>\n",
       "      <td>1422.69</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.16</td>\n",
       "      <td>8141.85</td>\n",
       "      <td>8.4876</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.55</td>\n",
       "      <td>23.2252</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20609</th>\n",
       "      <td>100</td>\n",
       "      <td>179</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.22</td>\n",
       "      <td>1599.36</td>\n",
       "      <td>1423.94</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.19</td>\n",
       "      <td>8138.58</td>\n",
       "      <td>8.5218</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.62</td>\n",
       "      <td>23.1685</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20610</th>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.64</td>\n",
       "      <td>1595.98</td>\n",
       "      <td>1416.45</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8138.98</td>\n",
       "      <td>8.5150</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.54</td>\n",
       "      <td>23.2345</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20611</th>\n",
       "      <td>100</td>\n",
       "      <td>181</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.25</td>\n",
       "      <td>1597.83</td>\n",
       "      <td>1414.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8139.30</td>\n",
       "      <td>8.5518</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.52</td>\n",
       "      <td>23.1774</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20612</th>\n",
       "      <td>100</td>\n",
       "      <td>182</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.52</td>\n",
       "      <td>1604.31</td>\n",
       "      <td>1417.73</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8140.87</td>\n",
       "      <td>8.4855</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.41</td>\n",
       "      <td>23.1289</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20613</th>\n",
       "      <td>100</td>\n",
       "      <td>183</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.34</td>\n",
       "      <td>1594.60</td>\n",
       "      <td>1427.27</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>8144.21</td>\n",
       "      <td>8.5006</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>23.0709</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20614</th>\n",
       "      <td>100</td>\n",
       "      <td>184</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.91</td>\n",
       "      <td>1598.88</td>\n",
       "      <td>1420.89</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.20</td>\n",
       "      <td>8142.28</td>\n",
       "      <td>8.4989</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.44</td>\n",
       "      <td>23.1229</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20615</th>\n",
       "      <td>100</td>\n",
       "      <td>185</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.95</td>\n",
       "      <td>1600.81</td>\n",
       "      <td>1420.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.20</td>\n",
       "      <td>8142.32</td>\n",
       "      <td>8.4804</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.60</td>\n",
       "      <td>23.2127</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20616</th>\n",
       "      <td>100</td>\n",
       "      <td>186</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.61</td>\n",
       "      <td>1593.55</td>\n",
       "      <td>1425.32</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.27</td>\n",
       "      <td>8138.08</td>\n",
       "      <td>8.4735</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.51</td>\n",
       "      <td>23.1173</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20617</th>\n",
       "      <td>100</td>\n",
       "      <td>187</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.63</td>\n",
       "      <td>1596.96</td>\n",
       "      <td>1421.49</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8140.49</td>\n",
       "      <td>8.5087</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.67</td>\n",
       "      <td>23.2308</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20618</th>\n",
       "      <td>100</td>\n",
       "      <td>188</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.19</td>\n",
       "      <td>1597.77</td>\n",
       "      <td>1426.57</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.21</td>\n",
       "      <td>8139.94</td>\n",
       "      <td>8.4814</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.36</td>\n",
       "      <td>23.0552</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20619</th>\n",
       "      <td>100</td>\n",
       "      <td>189</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.69</td>\n",
       "      <td>1599.85</td>\n",
       "      <td>1423.15</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>8139.78</td>\n",
       "      <td>8.4870</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.65</td>\n",
       "      <td>23.0591</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20620</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.12</td>\n",
       "      <td>1594.45</td>\n",
       "      <td>1426.04</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8142.28</td>\n",
       "      <td>8.5162</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.42</td>\n",
       "      <td>23.0603</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20621</th>\n",
       "      <td>100</td>\n",
       "      <td>191</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.69</td>\n",
       "      <td>1610.87</td>\n",
       "      <td>1427.19</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.28</td>\n",
       "      <td>8143.56</td>\n",
       "      <td>8.5092</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.39</td>\n",
       "      <td>23.1218</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20622</th>\n",
       "      <td>100</td>\n",
       "      <td>192</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.53</td>\n",
       "      <td>1601.23</td>\n",
       "      <td>1419.48</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.21</td>\n",
       "      <td>8143.46</td>\n",
       "      <td>8.4892</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.56</td>\n",
       "      <td>23.0770</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20623</th>\n",
       "      <td>100</td>\n",
       "      <td>193</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.09</td>\n",
       "      <td>1599.81</td>\n",
       "      <td>1428.93</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.19</td>\n",
       "      <td>8142.02</td>\n",
       "      <td>8.5424</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.47</td>\n",
       "      <td>23.0230</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20624</th>\n",
       "      <td>100</td>\n",
       "      <td>194</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.72</td>\n",
       "      <td>1597.29</td>\n",
       "      <td>1427.41</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8139.67</td>\n",
       "      <td>8.5215</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.38</td>\n",
       "      <td>23.1324</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20625</th>\n",
       "      <td>100</td>\n",
       "      <td>195</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.41</td>\n",
       "      <td>1600.04</td>\n",
       "      <td>1431.90</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.28</td>\n",
       "      <td>8142.90</td>\n",
       "      <td>8.5519</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.14</td>\n",
       "      <td>23.1923</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20626</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.49</td>\n",
       "      <td>1597.98</td>\n",
       "      <td>1428.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.60</td>\n",
       "      <td>8.4956</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>22.9735</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.54</td>\n",
       "      <td>1604.50</td>\n",
       "      <td>1433.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8136.50</td>\n",
       "      <td>8.5139</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.30</td>\n",
       "      <td>23.1594</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.42</td>\n",
       "      <td>1602.46</td>\n",
       "      <td>1428.18</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>8141.05</td>\n",
       "      <td>8.5646</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.44</td>\n",
       "      <td>22.9333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>100</td>\n",
       "      <td>199</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.23</td>\n",
       "      <td>1605.26</td>\n",
       "      <td>1426.53</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>8139.29</td>\n",
       "      <td>8.5389</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.29</td>\n",
       "      <td>23.0640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.85</td>\n",
       "      <td>1600.38</td>\n",
       "      <td>1432.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.33</td>\n",
       "      <td>8.5036</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.37</td>\n",
       "      <td>23.0522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20631 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  cycle  settings1  settings2  settings3      s1      s2       s3  \\\n",
       "0        1      1    -0.0007    -0.0004      100.0  518.67  641.82  1589.70   \n",
       "1        1      2     0.0019    -0.0003      100.0  518.67  642.15  1591.82   \n",
       "2        1      3    -0.0043     0.0003      100.0  518.67  642.35  1587.99   \n",
       "3        1      4     0.0007     0.0000      100.0  518.67  642.35  1582.79   \n",
       "4        1      5    -0.0019    -0.0002      100.0  518.67  642.37  1582.85   \n",
       "5        1      6    -0.0043    -0.0001      100.0  518.67  642.10  1584.47   \n",
       "6        1      7     0.0010     0.0001      100.0  518.67  642.48  1592.32   \n",
       "7        1      8    -0.0034     0.0003      100.0  518.67  642.56  1582.96   \n",
       "8        1      9     0.0008     0.0001      100.0  518.67  642.12  1590.98   \n",
       "9        1     10    -0.0033     0.0001      100.0  518.67  641.71  1591.24   \n",
       "10       1     11     0.0018    -0.0003      100.0  518.67  642.28  1581.75   \n",
       "11       1     12     0.0016     0.0002      100.0  518.67  642.06  1583.41   \n",
       "12       1     13    -0.0019     0.0004      100.0  518.67  643.07  1582.19   \n",
       "13       1     14     0.0009    -0.0000      100.0  518.67  642.35  1592.95   \n",
       "14       1     15    -0.0018    -0.0003      100.0  518.67  642.43  1583.82   \n",
       "15       1     16     0.0006     0.0005      100.0  518.67  642.13  1587.98   \n",
       "16       1     17     0.0002     0.0002      100.0  518.67  642.58  1584.96   \n",
       "17       1     18    -0.0031    -0.0001      100.0  518.67  642.62  1591.04   \n",
       "18       1     19     0.0032    -0.0003      100.0  518.67  641.79  1587.56   \n",
       "19       1     20    -0.0037     0.0001      100.0  518.67  643.04  1581.11   \n",
       "20       1     21    -0.0012     0.0001      100.0  518.67  642.37  1586.07   \n",
       "21       1     22     0.0002     0.0000      100.0  518.67  642.77  1592.93   \n",
       "22       1     23     0.0034    -0.0003      100.0  518.67  642.14  1588.19   \n",
       "23       1     24    -0.0010     0.0003      100.0  518.67  642.38  1590.83   \n",
       "24       1     25     0.0023    -0.0004      100.0  518.67  642.77  1594.10   \n",
       "25       1     26     0.0000     0.0002      100.0  518.67  642.16  1589.08   \n",
       "26       1     27    -0.0012    -0.0004      100.0  518.67  642.44  1590.47   \n",
       "27       1     28    -0.0024     0.0005      100.0  518.67  642.35  1582.84   \n",
       "28       1     29     0.0012    -0.0001      100.0  518.67  641.91  1584.83   \n",
       "29       1     30    -0.0022     0.0000      100.0  518.67  642.20  1593.52   \n",
       "...    ...    ...        ...        ...        ...     ...     ...      ...   \n",
       "20601  100    171    -0.0005    -0.0004      100.0  518.67  643.05  1593.56   \n",
       "20602  100    172    -0.0037     0.0001      100.0  518.67  642.97  1602.35   \n",
       "20603  100    173     0.0006     0.0004      100.0  518.67  643.40  1595.53   \n",
       "20604  100    174     0.0011     0.0002      100.0  518.67  642.91  1602.24   \n",
       "20605  100    175    -0.0013    -0.0005      100.0  518.67  642.85  1602.03   \n",
       "20606  100    176    -0.0017    -0.0003      100.0  518.67  643.33  1601.44   \n",
       "20607  100    177    -0.0011    -0.0005      100.0  518.67  643.34  1593.22   \n",
       "20608  100    178     0.0005    -0.0003      100.0  518.67  642.98  1594.80   \n",
       "20609  100    179     0.0020     0.0004      100.0  518.67  643.22  1599.36   \n",
       "20610  100    180    -0.0010     0.0001      100.0  518.67  643.64  1595.98   \n",
       "20611  100    181     0.0024    -0.0005      100.0  518.67  643.25  1597.83   \n",
       "20612  100    182     0.0007    -0.0001      100.0  518.67  643.52  1604.31   \n",
       "20613  100    183    -0.0011    -0.0002      100.0  518.67  643.34  1594.60   \n",
       "20614  100    184     0.0027    -0.0004      100.0  518.67  642.91  1598.88   \n",
       "20615  100    185    -0.0014     0.0004      100.0  518.67  643.95  1600.81   \n",
       "20616  100    186     0.0026     0.0004      100.0  518.67  643.61  1593.55   \n",
       "20617  100    187     0.0015     0.0002      100.0  518.67  643.63  1596.96   \n",
       "20618  100    188    -0.0008    -0.0002      100.0  518.67  643.19  1597.77   \n",
       "20619  100    189     0.0015     0.0001      100.0  518.67  643.69  1599.85   \n",
       "20620  100    190    -0.0001     0.0002      100.0  518.67  643.12  1594.45   \n",
       "20621  100    191    -0.0005    -0.0000      100.0  518.67  643.69  1610.87   \n",
       "20622  100    192    -0.0009     0.0001      100.0  518.67  643.53  1601.23   \n",
       "20623  100    193    -0.0001     0.0002      100.0  518.67  643.09  1599.81   \n",
       "20624  100    194    -0.0011     0.0003      100.0  518.67  643.72  1597.29   \n",
       "20625  100    195    -0.0002    -0.0001      100.0  518.67  643.41  1600.04   \n",
       "20626  100    196    -0.0004    -0.0003      100.0  518.67  643.49  1597.98   \n",
       "20627  100    197    -0.0016    -0.0005      100.0  518.67  643.54  1604.50   \n",
       "20628  100    198     0.0004     0.0000      100.0  518.67  643.42  1602.46   \n",
       "20629  100    199    -0.0011     0.0003      100.0  518.67  643.23  1605.26   \n",
       "20630  100    200    -0.0032    -0.0005      100.0  518.67  643.85  1600.38   \n",
       "\n",
       "            s4     s5  ...      s13      s14     s15   s16  s17   s18    s19  \\\n",
       "0      1400.60  14.62  ...  2388.02  8138.62  8.4195  0.03  392  2388  100.0   \n",
       "1      1403.14  14.62  ...  2388.07  8131.49  8.4318  0.03  392  2388  100.0   \n",
       "2      1404.20  14.62  ...  2388.03  8133.23  8.4178  0.03  390  2388  100.0   \n",
       "3      1401.87  14.62  ...  2388.08  8133.83  8.3682  0.03  392  2388  100.0   \n",
       "4      1406.22  14.62  ...  2388.04  8133.80  8.4294  0.03  393  2388  100.0   \n",
       "5      1398.37  14.62  ...  2388.03  8132.85  8.4108  0.03  391  2388  100.0   \n",
       "6      1397.77  14.62  ...  2388.03  8132.32  8.3974  0.03  392  2388  100.0   \n",
       "7      1400.97  14.62  ...  2388.03  8131.07  8.4076  0.03  391  2388  100.0   \n",
       "8      1394.80  14.62  ...  2388.05  8125.69  8.3728  0.03  392  2388  100.0   \n",
       "9      1400.46  14.62  ...  2388.06  8129.38  8.4286  0.03  393  2388  100.0   \n",
       "10     1400.64  14.62  ...  2388.01  8140.58  8.4340  0.03  392  2388  100.0   \n",
       "11     1400.15  14.62  ...  2388.02  8134.25  8.3938  0.03  391  2388  100.0   \n",
       "12     1400.83  14.62  ...  2388.08  8128.10  8.4152  0.03  393  2388  100.0   \n",
       "13     1399.16  14.62  ...  2388.00  8134.43  8.3964  0.03  393  2388  100.0   \n",
       "14     1402.13  14.62  ...  2388.08  8127.56  8.4199  0.03  391  2388  100.0   \n",
       "15     1404.50  14.62  ...  2388.07  8136.11  8.3936  0.03  392  2388  100.0   \n",
       "16     1399.95  14.62  ...  2388.04  8137.27  8.4542  0.03  392  2388  100.0   \n",
       "17     1396.12  14.62  ...  2388.07  8132.73  8.4028  0.03  392  2388  100.0   \n",
       "18     1400.35  14.62  ...  2388.03  8129.13  8.4321  0.03  391  2388  100.0   \n",
       "19     1405.23  14.62  ...  2388.02  8129.71  8.4210  0.03  392  2388  100.0   \n",
       "20     1398.13  14.62  ...  2388.08  8134.02  8.4049  0.03  392  2388  100.0   \n",
       "21     1400.57  14.62  ...  2388.03  8130.41  8.4034  0.03  392  2388  100.0   \n",
       "22     1394.75  14.62  ...  2388.05  8127.90  8.4240  0.03  392  2388  100.0   \n",
       "23     1398.81  14.62  ...  2388.03  8133.88  8.3891  0.03  392  2388  100.0   \n",
       "24     1399.39  14.62  ...  2388.02  8136.61  8.3917  0.03  393  2388  100.0   \n",
       "25     1396.07  14.62  ...  2388.06  8131.15  8.4260  0.03  394  2388  100.0   \n",
       "26     1401.84  14.62  ...  2388.13  8134.60  8.4046  0.03  393  2388  100.0   \n",
       "27     1399.13  14.62  ...  2388.08  8127.30  8.4323  0.03  390  2388  100.0   \n",
       "28     1400.99  14.62  ...  2388.06  8133.06  8.4189  0.03  393  2388  100.0   \n",
       "29     1396.08  14.62  ...  2388.00  8137.86  8.4065  0.03  390  2388  100.0   \n",
       "...        ...    ...  ...      ...      ...     ...   ...  ...   ...    ...   \n",
       "20601  1420.48  14.62  ...  2388.18  8144.03  8.5085  0.03  396  2388  100.0   \n",
       "20602  1424.93  14.62  ...  2388.19  8142.08  8.4970  0.03  394  2388  100.0   \n",
       "20603  1418.63  14.62  ...  2388.17  8143.13  8.4856  0.03  393  2388  100.0   \n",
       "20604  1425.52  14.62  ...  2388.15  8143.61  8.4990  0.03  395  2388  100.0   \n",
       "20605  1416.24  14.62  ...  2388.17  8140.88  8.4851  0.03  394  2388  100.0   \n",
       "20606  1421.40  14.62  ...  2388.19  8139.27  8.4405  0.03  396  2388  100.0   \n",
       "20607  1418.91  14.62  ...  2388.18  8142.95  8.5133  0.03  395  2388  100.0   \n",
       "20608  1422.69  14.62  ...  2388.16  8141.85  8.4876  0.03  395  2388  100.0   \n",
       "20609  1423.94  14.62  ...  2388.19  8138.58  8.5218  0.03  396  2388  100.0   \n",
       "20610  1416.45  14.62  ...  2388.22  8138.98  8.5150  0.03  395  2388  100.0   \n",
       "20611  1414.63  14.62  ...  2388.22  8139.30  8.5518  0.03  396  2388  100.0   \n",
       "20612  1417.73  14.62  ...  2388.22  8140.87  8.4855  0.03  396  2388  100.0   \n",
       "20613  1427.27  14.62  ...  2388.23  8144.21  8.5006  0.03  395  2388  100.0   \n",
       "20614  1420.89  14.62  ...  2388.20  8142.28  8.4989  0.03  396  2388  100.0   \n",
       "20615  1420.34  14.62  ...  2388.20  8142.32  8.4804  0.03  395  2388  100.0   \n",
       "20616  1425.32  14.62  ...  2388.27  8138.08  8.4735  0.03  394  2388  100.0   \n",
       "20617  1421.49  14.62  ...  2388.22  8140.49  8.5087  0.03  396  2388  100.0   \n",
       "20618  1426.57  14.62  ...  2388.21  8139.94  8.4814  0.03  395  2388  100.0   \n",
       "20619  1423.15  14.62  ...  2388.24  8139.78  8.4870  0.03  397  2388  100.0   \n",
       "20620  1426.04  14.62  ...  2388.26  8142.28  8.5162  0.03  395  2388  100.0   \n",
       "20621  1427.19  14.62  ...  2388.28  8143.56  8.5092  0.03  398  2388  100.0   \n",
       "20622  1419.48  14.62  ...  2388.21  8143.46  8.4892  0.03  397  2388  100.0   \n",
       "20623  1428.93  14.62  ...  2388.19  8142.02  8.5424  0.03  397  2388  100.0   \n",
       "20624  1427.41  14.62  ...  2388.22  8139.67  8.5215  0.03  394  2388  100.0   \n",
       "20625  1431.90  14.62  ...  2388.28  8142.90  8.5519  0.03  394  2388  100.0   \n",
       "20626  1428.63  14.62  ...  2388.26  8137.60  8.4956  0.03  397  2388  100.0   \n",
       "20627  1433.58  14.62  ...  2388.22  8136.50  8.5139  0.03  395  2388  100.0   \n",
       "20628  1428.18  14.62  ...  2388.24  8141.05  8.5646  0.03  398  2388  100.0   \n",
       "20629  1426.53  14.62  ...  2388.23  8139.29  8.5389  0.03  395  2388  100.0   \n",
       "20630  1432.14  14.62  ...  2388.26  8137.33  8.5036  0.03  396  2388  100.0   \n",
       "\n",
       "         s20      s21  ttf  \n",
       "0      39.06  23.4190  191  \n",
       "1      39.00  23.4236  190  \n",
       "2      38.95  23.3442  189  \n",
       "3      38.88  23.3739  188  \n",
       "4      38.90  23.4044  187  \n",
       "5      38.98  23.3669  186  \n",
       "6      39.10  23.3774  185  \n",
       "7      38.97  23.3106  184  \n",
       "8      39.05  23.4066  183  \n",
       "9      38.95  23.4694  182  \n",
       "10     38.94  23.4787  181  \n",
       "11     39.06  23.3660  180  \n",
       "12     38.93  23.2757  179  \n",
       "13     39.18  23.3826  178  \n",
       "14     38.99  23.3500  177  \n",
       "15     38.97  23.4550  176  \n",
       "16     38.81  23.3319  175  \n",
       "17     38.89  23.3987  174  \n",
       "18     38.80  23.3464  173  \n",
       "19     39.03  23.4220  172  \n",
       "20     39.09  23.3101  171  \n",
       "21     38.92  23.3792  170  \n",
       "22     38.94  23.4562  169  \n",
       "23     39.00  23.3696  168  \n",
       "24     38.95  23.4288  167  \n",
       "25     38.86  23.4149  166  \n",
       "26     38.99  23.4472  165  \n",
       "27     39.01  23.2841  164  \n",
       "28     38.93  23.3597  163  \n",
       "29     39.05  23.4110  162  \n",
       "...      ...      ...  ...  \n",
       "20601  38.81  23.1513   29  \n",
       "20602  38.49  23.1922   28  \n",
       "20603  38.42  23.1793   27  \n",
       "20604  38.80  23.1784   26  \n",
       "20605  38.54  23.0713   25  \n",
       "20606  38.46  23.1020   24  \n",
       "20607  38.60  23.0352   23  \n",
       "20608  38.55  23.2252   22  \n",
       "20609  38.62  23.1685   21  \n",
       "20610  38.54  23.2345   20  \n",
       "20611  38.52  23.1774   19  \n",
       "20612  38.41  23.1289   18  \n",
       "20613  38.49  23.0709   17  \n",
       "20614  38.44  23.1229   16  \n",
       "20615  38.60  23.2127   15  \n",
       "20616  38.51  23.1173   14  \n",
       "20617  38.67  23.2308   13  \n",
       "20618  38.36  23.0552   12  \n",
       "20619  38.65  23.0591   11  \n",
       "20620  38.42  23.0603   10  \n",
       "20621  38.39  23.1218    9  \n",
       "20622  38.56  23.0770    8  \n",
       "20623  38.47  23.0230    7  \n",
       "20624  38.38  23.1324    6  \n",
       "20625  38.14  23.1923    5  \n",
       "20626  38.49  22.9735    4  \n",
       "20627  38.30  23.1594    3  \n",
       "20628  38.44  22.9333    2  \n",
       "20629  38.29  23.0640    1  \n",
       "20630  38.37  23.0522    0  \n",
       "\n",
       "[20631 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata['ttf']=traindata.groupby('id')['cycle'].transform(max)-traindata['cycle']\n",
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_csv('PM_test.txt',sep=' ',header=None).drop([26,27],axis=1)\n",
    "testdata.columns=column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth= pd.read_csv('PM_truth.txt',sep=' ',header=None).drop([1],axis=1)\n",
    "truth.columns=[\"ttf\"]\n",
    "truth.index=truth.index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=testdata.groupby('id')['cycle'].max()+truth['ttf']\n",
    "a=pd.DataFrame(a)\n",
    "a.columns=['ttf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=testdata.merge(a,on=['id'],how=\"left\")\n",
    "testdata['ttf']=testdata['ttf']-testdata['cycle']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "period=30\n",
    "traindata['Due']=traindata['ttf'].apply(lambda x:1 if x<=period else 0)\n",
    "testdata[\"Due\"]=testdata['ttf'].apply(lambda x:1 if x<=period else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.drop(['ttf'],axis=1,inplace=True)\n",
    "testdata.drop(['ttf'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['settings1', 'settings2', 'settings3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11',\n",
    "                   's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "target='Due'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc=MinMaxScaler()\n",
    "traindata[features]=sc.fit_transform(traindata[features])\n",
    "testdata[features]=sc.transform(testdata[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>settings1</th>\n",
       "      <th>settings2</th>\n",
       "      <th>settings3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>Due</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268072</td>\n",
       "      <td>0.292784</td>\n",
       "      <td>0.272113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.169832</td>\n",
       "      <td>0.330512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.652720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.557471</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382530</td>\n",
       "      <td>0.463920</td>\n",
       "      <td>0.261985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.167097</td>\n",
       "      <td>0.278953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.667219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.304598</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406627</td>\n",
       "      <td>0.259865</td>\n",
       "      <td>0.316003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.160646</td>\n",
       "      <td>0.318199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.574979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.545977</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274096</td>\n",
       "      <td>0.434707</td>\n",
       "      <td>0.211850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.132883</td>\n",
       "      <td>0.184302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705426</td>\n",
       "      <td>0.707539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.440375</td>\n",
       "      <td>0.307394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.151925</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.794256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322289</td>\n",
       "      <td>0.233486</td>\n",
       "      <td>0.310432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.209722</td>\n",
       "      <td>0.419777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620155</td>\n",
       "      <td>0.807097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.591954</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256024</td>\n",
       "      <td>0.269675</td>\n",
       "      <td>0.302161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.177056</td>\n",
       "      <td>0.265102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.651477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560241</td>\n",
       "      <td>0.243078</td>\n",
       "      <td>0.313639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.145319</td>\n",
       "      <td>0.347441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612403</td>\n",
       "      <td>0.526788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.477654</td>\n",
       "      <td>0.285449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.177985</td>\n",
       "      <td>0.275106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.674399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.367470</td>\n",
       "      <td>0.278613</td>\n",
       "      <td>0.335584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.142533</td>\n",
       "      <td>0.365525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.629384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277108</td>\n",
       "      <td>0.369305</td>\n",
       "      <td>0.375591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.186655</td>\n",
       "      <td>0.264332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.774372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412651</td>\n",
       "      <td>0.303466</td>\n",
       "      <td>0.298785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.192641</td>\n",
       "      <td>0.497499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519380</td>\n",
       "      <td>0.604391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.424699</td>\n",
       "      <td>0.436015</td>\n",
       "      <td>0.234132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.169213</td>\n",
       "      <td>0.299731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.696631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.683908</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174699</td>\n",
       "      <td>0.360148</td>\n",
       "      <td>0.305537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.150635</td>\n",
       "      <td>0.412466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.624413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551205</td>\n",
       "      <td>0.219533</td>\n",
       "      <td>0.387914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.153628</td>\n",
       "      <td>0.369758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689922</td>\n",
       "      <td>0.728804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.327665</td>\n",
       "      <td>0.268062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.175870</td>\n",
       "      <td>0.307811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.574289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.477218</td>\n",
       "      <td>0.309251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.157240</td>\n",
       "      <td>0.302039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.669705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.695402</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280120</td>\n",
       "      <td>0.373883</td>\n",
       "      <td>0.211006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.144287</td>\n",
       "      <td>0.381301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620155</td>\n",
       "      <td>0.776029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352410</td>\n",
       "      <td>0.431437</td>\n",
       "      <td>0.279541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.175147</td>\n",
       "      <td>0.247018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.656448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.502725</td>\n",
       "      <td>0.289332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.189235</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.738194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286145</td>\n",
       "      <td>0.393285</td>\n",
       "      <td>0.233288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.161059</td>\n",
       "      <td>0.388996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.423588</td>\n",
       "      <td>0.330689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.178863</td>\n",
       "      <td>0.306656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.763601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.257249</td>\n",
       "      <td>0.284943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.141191</td>\n",
       "      <td>0.413236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.538387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210843</td>\n",
       "      <td>0.300632</td>\n",
       "      <td>0.316340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.170915</td>\n",
       "      <td>0.361678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612403</td>\n",
       "      <td>0.642778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.373563</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298193</td>\n",
       "      <td>0.490081</td>\n",
       "      <td>0.233457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.195686</td>\n",
       "      <td>0.313967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705426</td>\n",
       "      <td>0.713615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20601</th>\n",
       "      <td>100</td>\n",
       "      <td>171</td>\n",
       "      <td>0.471264</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.490953</td>\n",
       "      <td>0.645341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.227526</td>\n",
       "      <td>0.706426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519380</td>\n",
       "      <td>0.355012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20602</th>\n",
       "      <td>100</td>\n",
       "      <td>172</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.682581</td>\n",
       "      <td>0.720459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.217463</td>\n",
       "      <td>0.662178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271318</td>\n",
       "      <td>0.411489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20603</th>\n",
       "      <td>100</td>\n",
       "      <td>173</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.659639</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>0.614112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.222882</td>\n",
       "      <td>0.618315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217054</td>\n",
       "      <td>0.393676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20604</th>\n",
       "      <td>100</td>\n",
       "      <td>174</td>\n",
       "      <td>0.563218</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.680183</td>\n",
       "      <td>0.730419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.225359</td>\n",
       "      <td>0.669873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.392433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20605</th>\n",
       "      <td>100</td>\n",
       "      <td>175</td>\n",
       "      <td>0.425287</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.675605</td>\n",
       "      <td>0.573768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.211271</td>\n",
       "      <td>0.616391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310078</td>\n",
       "      <td>0.244546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20606</th>\n",
       "      <td>100</td>\n",
       "      <td>176</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.662743</td>\n",
       "      <td>0.660871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.202962</td>\n",
       "      <td>0.444786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248062</td>\n",
       "      <td>0.286937</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20607</th>\n",
       "      <td>100</td>\n",
       "      <td>177</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641566</td>\n",
       "      <td>0.483540</td>\n",
       "      <td>0.618839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.221953</td>\n",
       "      <td>0.724894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>0.194698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20608</th>\n",
       "      <td>100</td>\n",
       "      <td>178</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533133</td>\n",
       "      <td>0.517986</td>\n",
       "      <td>0.682647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.216276</td>\n",
       "      <td>0.626010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317829</td>\n",
       "      <td>0.457056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20609</th>\n",
       "      <td>100</td>\n",
       "      <td>179</td>\n",
       "      <td>0.614943</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605422</td>\n",
       "      <td>0.617397</td>\n",
       "      <td>0.703747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.199401</td>\n",
       "      <td>0.757599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.378763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20610</th>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731928</td>\n",
       "      <td>0.543710</td>\n",
       "      <td>0.577313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.201466</td>\n",
       "      <td>0.731435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310078</td>\n",
       "      <td>0.469898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20611</th>\n",
       "      <td>100</td>\n",
       "      <td>181</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614458</td>\n",
       "      <td>0.584042</td>\n",
       "      <td>0.546590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.203117</td>\n",
       "      <td>0.873028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294574</td>\n",
       "      <td>0.391052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20612</th>\n",
       "      <td>100</td>\n",
       "      <td>182</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695783</td>\n",
       "      <td>0.725311</td>\n",
       "      <td>0.598920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.211219</td>\n",
       "      <td>0.617930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.324082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20613</th>\n",
       "      <td>100</td>\n",
       "      <td>183</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641566</td>\n",
       "      <td>0.513625</td>\n",
       "      <td>0.759959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.228455</td>\n",
       "      <td>0.676029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271318</td>\n",
       "      <td>0.243993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20614</th>\n",
       "      <td>100</td>\n",
       "      <td>184</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.606933</td>\n",
       "      <td>0.652262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.218495</td>\n",
       "      <td>0.669488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.315797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20615</th>\n",
       "      <td>100</td>\n",
       "      <td>185</td>\n",
       "      <td>0.419540</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.649008</td>\n",
       "      <td>0.642978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.218702</td>\n",
       "      <td>0.598307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>0.439796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20616</th>\n",
       "      <td>100</td>\n",
       "      <td>186</td>\n",
       "      <td>0.649425</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.490735</td>\n",
       "      <td>0.727043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.196821</td>\n",
       "      <td>0.571758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286822</td>\n",
       "      <td>0.308064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20617</th>\n",
       "      <td>100</td>\n",
       "      <td>187</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728916</td>\n",
       "      <td>0.565075</td>\n",
       "      <td>0.662390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.209258</td>\n",
       "      <td>0.707195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410853</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20618</th>\n",
       "      <td>100</td>\n",
       "      <td>188</td>\n",
       "      <td>0.454023</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596386</td>\n",
       "      <td>0.582734</td>\n",
       "      <td>0.748143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.206420</td>\n",
       "      <td>0.602155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>0.222314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20619</th>\n",
       "      <td>100</td>\n",
       "      <td>189</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.628079</td>\n",
       "      <td>0.690412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.205594</td>\n",
       "      <td>0.623701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20620</th>\n",
       "      <td>100</td>\n",
       "      <td>190</td>\n",
       "      <td>0.494253</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.575301</td>\n",
       "      <td>0.510355</td>\n",
       "      <td>0.739196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.218495</td>\n",
       "      <td>0.736052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217054</td>\n",
       "      <td>0.229357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20621</th>\n",
       "      <td>100</td>\n",
       "      <td>191</td>\n",
       "      <td>0.471264</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.868324</td>\n",
       "      <td>0.758609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.225101</td>\n",
       "      <td>0.709119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193798</td>\n",
       "      <td>0.314278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20622</th>\n",
       "      <td>100</td>\n",
       "      <td>192</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.658164</td>\n",
       "      <td>0.628460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.224585</td>\n",
       "      <td>0.632166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.252416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20623</th>\n",
       "      <td>100</td>\n",
       "      <td>193</td>\n",
       "      <td>0.494253</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566265</td>\n",
       "      <td>0.627207</td>\n",
       "      <td>0.787981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.217153</td>\n",
       "      <td>0.836860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.177851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20624</th>\n",
       "      <td>100</td>\n",
       "      <td>194</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756024</td>\n",
       "      <td>0.572269</td>\n",
       "      <td>0.762323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.205026</td>\n",
       "      <td>0.756445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.328915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20625</th>\n",
       "      <td>100</td>\n",
       "      <td>195</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.632221</td>\n",
       "      <td>0.838116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.221695</td>\n",
       "      <td>0.873413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20626</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>0.477011</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.587312</td>\n",
       "      <td>0.782917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.194344</td>\n",
       "      <td>0.656791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271318</td>\n",
       "      <td>0.109500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>0.408046</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.701807</td>\n",
       "      <td>0.729453</td>\n",
       "      <td>0.866475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.188668</td>\n",
       "      <td>0.727203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124031</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.522989</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665663</td>\n",
       "      <td>0.684979</td>\n",
       "      <td>0.775321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.212148</td>\n",
       "      <td>0.922278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.053991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>100</td>\n",
       "      <td>199</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608434</td>\n",
       "      <td>0.746021</td>\n",
       "      <td>0.747468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.203065</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.234466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>0.316092</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.639634</td>\n",
       "      <td>0.842167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.192951</td>\n",
       "      <td>0.687572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178295</td>\n",
       "      <td>0.218172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20631 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  cycle  settings1  settings2  settings3   s1        s2        s3  \\\n",
       "0        1      1   0.459770   0.166667        0.0  0.0  0.183735  0.406802   \n",
       "1        1      2   0.609195   0.250000        0.0  0.0  0.283133  0.453019   \n",
       "2        1      3   0.252874   0.750000        0.0  0.0  0.343373  0.369523   \n",
       "3        1      4   0.540230   0.500000        0.0  0.0  0.343373  0.256159   \n",
       "4        1      5   0.390805   0.333333        0.0  0.0  0.349398  0.257467   \n",
       "5        1      6   0.252874   0.416667        0.0  0.0  0.268072  0.292784   \n",
       "6        1      7   0.557471   0.583333        0.0  0.0  0.382530  0.463920   \n",
       "7        1      8   0.304598   0.750000        0.0  0.0  0.406627  0.259865   \n",
       "8        1      9   0.545977   0.583333        0.0  0.0  0.274096  0.434707   \n",
       "9        1     10   0.310345   0.583333        0.0  0.0  0.150602  0.440375   \n",
       "10       1     11   0.603448   0.250000        0.0  0.0  0.322289  0.233486   \n",
       "11       1     12   0.591954   0.666667        0.0  0.0  0.256024  0.269675   \n",
       "12       1     13   0.390805   0.833333        0.0  0.0  0.560241  0.243078   \n",
       "13       1     14   0.551724   0.500000        0.0  0.0  0.343373  0.477654   \n",
       "14       1     15   0.396552   0.250000        0.0  0.0  0.367470  0.278613   \n",
       "15       1     16   0.534483   0.916667        0.0  0.0  0.277108  0.369305   \n",
       "16       1     17   0.511494   0.666667        0.0  0.0  0.412651  0.303466   \n",
       "17       1     18   0.321839   0.416667        0.0  0.0  0.424699  0.436015   \n",
       "18       1     19   0.683908   0.250000        0.0  0.0  0.174699  0.360148   \n",
       "19       1     20   0.287356   0.583333        0.0  0.0  0.551205  0.219533   \n",
       "20       1     21   0.431034   0.583333        0.0  0.0  0.349398  0.327665   \n",
       "21       1     22   0.511494   0.500000        0.0  0.0  0.469880  0.477218   \n",
       "22       1     23   0.695402   0.250000        0.0  0.0  0.280120  0.373883   \n",
       "23       1     24   0.442529   0.750000        0.0  0.0  0.352410  0.431437   \n",
       "24       1     25   0.632184   0.166667        0.0  0.0  0.469880  0.502725   \n",
       "25       1     26   0.500000   0.666667        0.0  0.0  0.286145  0.393285   \n",
       "26       1     27   0.431034   0.166667        0.0  0.0  0.370482  0.423588   \n",
       "27       1     28   0.362069   0.916667        0.0  0.0  0.343373  0.257249   \n",
       "28       1     29   0.568966   0.416667        0.0  0.0  0.210843  0.300632   \n",
       "29       1     30   0.373563   0.500000        0.0  0.0  0.298193  0.490081   \n",
       "...    ...    ...        ...        ...        ...  ...       ...       ...   \n",
       "20601  100    171   0.471264   0.166667        0.0  0.0  0.554217  0.490953   \n",
       "20602  100    172   0.287356   0.583333        0.0  0.0  0.530120  0.682581   \n",
       "20603  100    173   0.534483   0.833333        0.0  0.0  0.659639  0.533900   \n",
       "20604  100    174   0.563218   0.666667        0.0  0.0  0.512048  0.680183   \n",
       "20605  100    175   0.425287   0.083333        0.0  0.0  0.493976  0.675605   \n",
       "20606  100    176   0.402299   0.250000        0.0  0.0  0.638554  0.662743   \n",
       "20607  100    177   0.436782   0.083333        0.0  0.0  0.641566  0.483540   \n",
       "20608  100    178   0.528736   0.250000        0.0  0.0  0.533133  0.517986   \n",
       "20609  100    179   0.614943   0.833333        0.0  0.0  0.605422  0.617397   \n",
       "20610  100    180   0.442529   0.583333        0.0  0.0  0.731928  0.543710   \n",
       "20611  100    181   0.637931   0.083333        0.0  0.0  0.614458  0.584042   \n",
       "20612  100    182   0.540230   0.416667        0.0  0.0  0.695783  0.725311   \n",
       "20613  100    183   0.436782   0.333333        0.0  0.0  0.641566  0.513625   \n",
       "20614  100    184   0.655172   0.166667        0.0  0.0  0.512048  0.606933   \n",
       "20615  100    185   0.419540   0.833333        0.0  0.0  0.825301  0.649008   \n",
       "20616  100    186   0.649425   0.833333        0.0  0.0  0.722892  0.490735   \n",
       "20617  100    187   0.586207   0.666667        0.0  0.0  0.728916  0.565075   \n",
       "20618  100    188   0.454023   0.333333        0.0  0.0  0.596386  0.582734   \n",
       "20619  100    189   0.586207   0.583333        0.0  0.0  0.746988  0.628079   \n",
       "20620  100    190   0.494253   0.666667        0.0  0.0  0.575301  0.510355   \n",
       "20621  100    191   0.471264   0.500000        0.0  0.0  0.746988  0.868324   \n",
       "20622  100    192   0.448276   0.583333        0.0  0.0  0.698795  0.658164   \n",
       "20623  100    193   0.494253   0.666667        0.0  0.0  0.566265  0.627207   \n",
       "20624  100    194   0.436782   0.750000        0.0  0.0  0.756024  0.572269   \n",
       "20625  100    195   0.488506   0.416667        0.0  0.0  0.662651  0.632221   \n",
       "20626  100    196   0.477011   0.250000        0.0  0.0  0.686747  0.587312   \n",
       "20627  100    197   0.408046   0.083333        0.0  0.0  0.701807  0.729453   \n",
       "20628  100    198   0.522989   0.500000        0.0  0.0  0.665663  0.684979   \n",
       "20629  100    199   0.436782   0.750000        0.0  0.0  0.608434  0.746021   \n",
       "20630  100    200   0.316092   0.083333        0.0  0.0  0.795181  0.639634   \n",
       "\n",
       "             s4   s5  ...       s13       s14       s15  s16       s17  s18  \\\n",
       "0      0.309757  0.0  ...  0.205882  0.199608  0.363986  0.0  0.333333  0.0   \n",
       "1      0.352633  0.0  ...  0.279412  0.162813  0.411312  0.0  0.333333  0.0   \n",
       "2      0.370527  0.0  ...  0.220588  0.171793  0.357445  0.0  0.166667  0.0   \n",
       "3      0.331195  0.0  ...  0.294118  0.174889  0.166603  0.0  0.333333  0.0   \n",
       "4      0.404625  0.0  ...  0.235294  0.174734  0.402078  0.0  0.416667  0.0   \n",
       "5      0.272113  0.0  ...  0.220588  0.169832  0.330512  0.0  0.250000  0.0   \n",
       "6      0.261985  0.0  ...  0.220588  0.167097  0.278953  0.0  0.333333  0.0   \n",
       "7      0.316003  0.0  ...  0.220588  0.160646  0.318199  0.0  0.250000  0.0   \n",
       "8      0.211850  0.0  ...  0.250000  0.132883  0.184302  0.0  0.333333  0.0   \n",
       "9      0.307394  0.0  ...  0.264706  0.151925  0.399000  0.0  0.416667  0.0   \n",
       "10     0.310432  0.0  ...  0.191176  0.209722  0.419777  0.0  0.333333  0.0   \n",
       "11     0.302161  0.0  ...  0.205882  0.177056  0.265102  0.0  0.250000  0.0   \n",
       "12     0.313639  0.0  ...  0.294118  0.145319  0.347441  0.0  0.416667  0.0   \n",
       "13     0.285449  0.0  ...  0.176471  0.177985  0.275106  0.0  0.416667  0.0   \n",
       "14     0.335584  0.0  ...  0.294118  0.142533  0.365525  0.0  0.250000  0.0   \n",
       "15     0.375591  0.0  ...  0.279412  0.186655  0.264332  0.0  0.333333  0.0   \n",
       "16     0.298785  0.0  ...  0.235294  0.192641  0.497499  0.0  0.333333  0.0   \n",
       "17     0.234132  0.0  ...  0.279412  0.169213  0.299731  0.0  0.333333  0.0   \n",
       "18     0.305537  0.0  ...  0.220588  0.150635  0.412466  0.0  0.250000  0.0   \n",
       "19     0.387914  0.0  ...  0.205882  0.153628  0.369758  0.0  0.333333  0.0   \n",
       "20     0.268062  0.0  ...  0.294118  0.175870  0.307811  0.0  0.333333  0.0   \n",
       "21     0.309251  0.0  ...  0.220588  0.157240  0.302039  0.0  0.333333  0.0   \n",
       "22     0.211006  0.0  ...  0.250000  0.144287  0.381301  0.0  0.333333  0.0   \n",
       "23     0.279541  0.0  ...  0.220588  0.175147  0.247018  0.0  0.333333  0.0   \n",
       "24     0.289332  0.0  ...  0.205882  0.189235  0.257022  0.0  0.416667  0.0   \n",
       "25     0.233288  0.0  ...  0.264706  0.161059  0.388996  0.0  0.500000  0.0   \n",
       "26     0.330689  0.0  ...  0.367647  0.178863  0.306656  0.0  0.416667  0.0   \n",
       "27     0.284943  0.0  ...  0.294118  0.141191  0.413236  0.0  0.166667  0.0   \n",
       "28     0.316340  0.0  ...  0.264706  0.170915  0.361678  0.0  0.416667  0.0   \n",
       "29     0.233457  0.0  ...  0.176471  0.195686  0.313967  0.0  0.166667  0.0   \n",
       "...         ...  ...  ...       ...       ...       ...  ...       ...  ...   \n",
       "20601  0.645341  0.0  ...  0.441176  0.227526  0.706426  0.0  0.666667  0.0   \n",
       "20602  0.720459  0.0  ...  0.455882  0.217463  0.662178  0.0  0.500000  0.0   \n",
       "20603  0.614112  0.0  ...  0.426471  0.222882  0.618315  0.0  0.416667  0.0   \n",
       "20604  0.730419  0.0  ...  0.397059  0.225359  0.669873  0.0  0.583333  0.0   \n",
       "20605  0.573768  0.0  ...  0.426471  0.211271  0.616391  0.0  0.500000  0.0   \n",
       "20606  0.660871  0.0  ...  0.455882  0.202962  0.444786  0.0  0.666667  0.0   \n",
       "20607  0.618839  0.0  ...  0.441176  0.221953  0.724894  0.0  0.583333  0.0   \n",
       "20608  0.682647  0.0  ...  0.411765  0.216276  0.626010  0.0  0.583333  0.0   \n",
       "20609  0.703747  0.0  ...  0.455882  0.199401  0.757599  0.0  0.666667  0.0   \n",
       "20610  0.577313  0.0  ...  0.500000  0.201466  0.731435  0.0  0.583333  0.0   \n",
       "20611  0.546590  0.0  ...  0.500000  0.203117  0.873028  0.0  0.666667  0.0   \n",
       "20612  0.598920  0.0  ...  0.500000  0.211219  0.617930  0.0  0.666667  0.0   \n",
       "20613  0.759959  0.0  ...  0.514706  0.228455  0.676029  0.0  0.583333  0.0   \n",
       "20614  0.652262  0.0  ...  0.470588  0.218495  0.669488  0.0  0.666667  0.0   \n",
       "20615  0.642978  0.0  ...  0.470588  0.218702  0.598307  0.0  0.583333  0.0   \n",
       "20616  0.727043  0.0  ...  0.573529  0.196821  0.571758  0.0  0.500000  0.0   \n",
       "20617  0.662390  0.0  ...  0.500000  0.209258  0.707195  0.0  0.666667  0.0   \n",
       "20618  0.748143  0.0  ...  0.485294  0.206420  0.602155  0.0  0.583333  0.0   \n",
       "20619  0.690412  0.0  ...  0.529412  0.205594  0.623701  0.0  0.750000  0.0   \n",
       "20620  0.739196  0.0  ...  0.558824  0.218495  0.736052  0.0  0.583333  0.0   \n",
       "20621  0.758609  0.0  ...  0.588235  0.225101  0.709119  0.0  0.833333  0.0   \n",
       "20622  0.628460  0.0  ...  0.485294  0.224585  0.632166  0.0  0.750000  0.0   \n",
       "20623  0.787981  0.0  ...  0.455882  0.217153  0.836860  0.0  0.750000  0.0   \n",
       "20624  0.762323  0.0  ...  0.500000  0.205026  0.756445  0.0  0.500000  0.0   \n",
       "20625  0.838116  0.0  ...  0.588235  0.221695  0.873413  0.0  0.500000  0.0   \n",
       "20626  0.782917  0.0  ...  0.558824  0.194344  0.656791  0.0  0.750000  0.0   \n",
       "20627  0.866475  0.0  ...  0.500000  0.188668  0.727203  0.0  0.583333  0.0   \n",
       "20628  0.775321  0.0  ...  0.529412  0.212148  0.922278  0.0  0.833333  0.0   \n",
       "20629  0.747468  0.0  ...  0.514706  0.203065  0.823394  0.0  0.583333  0.0   \n",
       "20630  0.842167  0.0  ...  0.558824  0.192951  0.687572  0.0  0.666667  0.0   \n",
       "\n",
       "       s19       s20       s21  Due  \n",
       "0      0.0  0.713178  0.724662    0  \n",
       "1      0.0  0.666667  0.731014    0  \n",
       "2      0.0  0.627907  0.621375    0  \n",
       "3      0.0  0.573643  0.662386    0  \n",
       "4      0.0  0.589147  0.704502    0  \n",
       "5      0.0  0.651163  0.652720    0  \n",
       "6      0.0  0.744186  0.667219    0  \n",
       "7      0.0  0.643411  0.574979    0  \n",
       "8      0.0  0.705426  0.707539    0  \n",
       "9      0.0  0.627907  0.794256    0  \n",
       "10     0.0  0.620155  0.807097    0  \n",
       "11     0.0  0.713178  0.651477    0  \n",
       "12     0.0  0.612403  0.526788    0  \n",
       "13     0.0  0.806202  0.674399    0  \n",
       "14     0.0  0.658915  0.629384    0  \n",
       "15     0.0  0.643411  0.774372    0  \n",
       "16     0.0  0.519380  0.604391    0  \n",
       "17     0.0  0.581395  0.696631    0  \n",
       "18     0.0  0.511628  0.624413    0  \n",
       "19     0.0  0.689922  0.728804    0  \n",
       "20     0.0  0.736434  0.574289    0  \n",
       "21     0.0  0.604651  0.669705    0  \n",
       "22     0.0  0.620155  0.776029    0  \n",
       "23     0.0  0.666667  0.656448    0  \n",
       "24     0.0  0.627907  0.738194    0  \n",
       "25     0.0  0.558140  0.719000    0  \n",
       "26     0.0  0.658915  0.763601    0  \n",
       "27     0.0  0.674419  0.538387    0  \n",
       "28     0.0  0.612403  0.642778    0  \n",
       "29     0.0  0.705426  0.713615    0  \n",
       "...    ...       ...       ...  ...  \n",
       "20601  0.0  0.519380  0.355012    1  \n",
       "20602  0.0  0.271318  0.411489    1  \n",
       "20603  0.0  0.217054  0.393676    1  \n",
       "20604  0.0  0.511628  0.392433    1  \n",
       "20605  0.0  0.310078  0.244546    1  \n",
       "20606  0.0  0.248062  0.286937    1  \n",
       "20607  0.0  0.356589  0.194698    1  \n",
       "20608  0.0  0.317829  0.457056    1  \n",
       "20609  0.0  0.372093  0.378763    1  \n",
       "20610  0.0  0.310078  0.469898    1  \n",
       "20611  0.0  0.294574  0.391052    1  \n",
       "20612  0.0  0.209302  0.324082    1  \n",
       "20613  0.0  0.271318  0.243993    1  \n",
       "20614  0.0  0.232558  0.315797    1  \n",
       "20615  0.0  0.356589  0.439796    1  \n",
       "20616  0.0  0.286822  0.308064    1  \n",
       "20617  0.0  0.410853  0.464789    1  \n",
       "20618  0.0  0.170543  0.222314    1  \n",
       "20619  0.0  0.395349  0.227700    1  \n",
       "20620  0.0  0.217054  0.229357    1  \n",
       "20621  0.0  0.193798  0.314278    1  \n",
       "20622  0.0  0.325581  0.252416    1  \n",
       "20623  0.0  0.255814  0.177851    1  \n",
       "20624  0.0  0.186047  0.328915    1  \n",
       "20625  0.0  0.000000  0.411627    1  \n",
       "20626  0.0  0.271318  0.109500    1  \n",
       "20627  0.0  0.124031  0.366197    1  \n",
       "20628  0.0  0.232558  0.053991    1  \n",
       "20629  0.0  0.116279  0.234466    1  \n",
       "20630  0.0  0.178295  0.218172    1  \n",
       "\n",
       "[20631 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=traindata.iloc[:,0:26].values\n",
    "y_train=traindata.iloc[:,26:27].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 26 ,kernel_initializer = \"random_uniform\",activation =\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 300 ,kernel_initializer = \"random_uniform\",activation =\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 300 , kernel_initializer = \"random_uniform\",activation =\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 1 , kernel_initializer = \"random_uniform\",activation =\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"rmsprop\",loss=\"binary_crossentropy\" ,metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=testdata.iloc[:,0:26].values\n",
    "y_test=testdata.iloc[:,26:27].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prince\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 20631 samples, validate on 13096 samples\n",
      "Epoch 1/1000\n",
      "20631/20631 [==============================] - 1s 39us/sample - loss: 0.3508 - accuracy: 0.8545 - val_loss: 0.0797 - val_accuracy: 0.9708\n",
      "Epoch 2/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.2525 - accuracy: 0.8747 - val_loss: 0.1756 - val_accuracy: 0.9026\n",
      "Epoch 3/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.2208 - accuracy: 0.8908 - val_loss: 0.0750 - val_accuracy: 0.9693\n",
      "Epoch 4/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1979 - accuracy: 0.9081 - val_loss: 0.0520 - val_accuracy: 0.9805\n",
      "Epoch 5/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1767 - accuracy: 0.9212 - val_loss: 0.0518 - val_accuracy: 0.9772\n",
      "Epoch 6/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.1629 - accuracy: 0.9283 - val_loss: 0.0485 - val_accuracy: 0.9788\n",
      "Epoch 7/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.1510 - accuracy: 0.9337 - val_loss: 0.0396 - val_accuracy: 0.9842\n",
      "Epoch 8/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.1469 - accuracy: 0.9377 - val_loss: 0.0408 - val_accuracy: 0.9853\n",
      "Epoch 9/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.1460 - accuracy: 0.9370 - val_loss: 0.0776 - val_accuracy: 0.9746\n",
      "Epoch 10/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1394 - accuracy: 0.9400 - val_loss: 0.0411 - val_accuracy: 0.9843\n",
      "Epoch 11/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.1373 - accuracy: 0.9418 - val_loss: 0.0426 - val_accuracy: 0.9833\n",
      "Epoch 12/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1335 - accuracy: 0.9432 - val_loss: 0.0391 - val_accuracy: 0.9836\n",
      "Epoch 13/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1303 - accuracy: 0.9444 - val_loss: 0.0393 - val_accuracy: 0.9854\n",
      "Epoch 14/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1285 - accuracy: 0.9447 - val_loss: 0.0906 - val_accuracy: 0.9594\n",
      "Epoch 15/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1295 - accuracy: 0.9443 - val_loss: 0.0426 - val_accuracy: 0.9842\n",
      "Epoch 16/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1260 - accuracy: 0.9467 - val_loss: 0.0560 - val_accuracy: 0.9775\n",
      "Epoch 17/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1256 - accuracy: 0.9475 - val_loss: 0.0392 - val_accuracy: 0.9858\n",
      "Epoch 18/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1242 - accuracy: 0.9470 - val_loss: 0.0860 - val_accuracy: 0.9620\n",
      "Epoch 19/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1225 - accuracy: 0.9474 - val_loss: 0.0401 - val_accuracy: 0.9837\n",
      "Epoch 20/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1190 - accuracy: 0.9485 - val_loss: 0.0446 - val_accuracy: 0.9846\n",
      "Epoch 21/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1198 - accuracy: 0.9485 - val_loss: 0.0486 - val_accuracy: 0.9814\n",
      "Epoch 22/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1201 - accuracy: 0.9489 - val_loss: 0.0387 - val_accuracy: 0.9855\n",
      "Epoch 23/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1158 - accuracy: 0.9506 - val_loss: 0.0373 - val_accuracy: 0.9860\n",
      "Epoch 24/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1164 - accuracy: 0.9497 - val_loss: 0.0450 - val_accuracy: 0.9847\n",
      "Epoch 25/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1144 - accuracy: 0.9513 - val_loss: 0.0711 - val_accuracy: 0.9717\n",
      "Epoch 26/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1176 - accuracy: 0.9482 - val_loss: 0.0504 - val_accuracy: 0.9806\n",
      "Epoch 27/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1142 - accuracy: 0.9523 - val_loss: 0.0397 - val_accuracy: 0.9853\n",
      "Epoch 28/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1140 - accuracy: 0.9531 - val_loss: 0.0470 - val_accuracy: 0.9859\n",
      "Epoch 29/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1120 - accuracy: 0.9530 - val_loss: 0.0409 - val_accuracy: 0.9842\n",
      "Epoch 30/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1129 - accuracy: 0.9536 - val_loss: 0.0668 - val_accuracy: 0.9766\n",
      "Epoch 31/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1107 - accuracy: 0.9513 - val_loss: 0.0415 - val_accuracy: 0.9837\n",
      "Epoch 32/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1118 - accuracy: 0.9530 - val_loss: 0.0542 - val_accuracy: 0.9816\n",
      "Epoch 33/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1112 - accuracy: 0.9525 - val_loss: 0.0534 - val_accuracy: 0.9806\n",
      "Epoch 34/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1136 - accuracy: 0.9498 - val_loss: 0.0440 - val_accuracy: 0.9838\n",
      "Epoch 35/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1130 - accuracy: 0.9524 - val_loss: 0.0662 - val_accuracy: 0.9782\n",
      "Epoch 36/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1077 - accuracy: 0.9528 - val_loss: 0.0425 - val_accuracy: 0.9842\n",
      "Epoch 37/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1101 - accuracy: 0.9524 - val_loss: 0.0364 - val_accuracy: 0.9856\n",
      "Epoch 38/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1086 - accuracy: 0.9540 - val_loss: 0.0449 - val_accuracy: 0.9827\n",
      "Epoch 39/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1096 - accuracy: 0.9522 - val_loss: 0.0569 - val_accuracy: 0.9780\n",
      "Epoch 40/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1105 - accuracy: 0.9537 - val_loss: 0.0495 - val_accuracy: 0.9808\n",
      "Epoch 41/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1086 - accuracy: 0.9532 - val_loss: 0.0412 - val_accuracy: 0.9834\n",
      "Epoch 42/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1079 - accuracy: 0.9547 - val_loss: 0.0550 - val_accuracy: 0.9768\n",
      "Epoch 43/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1074 - accuracy: 0.9556 - val_loss: 0.0595 - val_accuracy: 0.9786\n",
      "Epoch 44/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1053 - accuracy: 0.9555 - val_loss: 0.0825 - val_accuracy: 0.9661\n",
      "Epoch 45/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1080 - accuracy: 0.9557 - val_loss: 0.0443 - val_accuracy: 0.9833\n",
      "Epoch 46/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1041 - accuracy: 0.9553 - val_loss: 0.0507 - val_accuracy: 0.9829\n",
      "Epoch 47/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1055 - accuracy: 0.9547 - val_loss: 0.0475 - val_accuracy: 0.9823\n",
      "Epoch 48/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1045 - accuracy: 0.9550 - val_loss: 0.0436 - val_accuracy: 0.9847\n",
      "Epoch 49/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1040 - accuracy: 0.9557 - val_loss: 0.0486 - val_accuracy: 0.9811\n",
      "Epoch 50/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1056 - accuracy: 0.9542 - val_loss: 0.0377 - val_accuracy: 0.9859\n",
      "Epoch 51/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1052 - accuracy: 0.9563 - val_loss: 0.0440 - val_accuracy: 0.9834\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1046 - accuracy: 0.9546 - val_loss: 0.0434 - val_accuracy: 0.9830\n",
      "Epoch 53/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1032 - accuracy: 0.9570 - val_loss: 0.0420 - val_accuracy: 0.9859\n",
      "Epoch 54/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1034 - accuracy: 0.9572 - val_loss: 0.0410 - val_accuracy: 0.9843\n",
      "Epoch 55/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1068 - accuracy: 0.9536 - val_loss: 0.0486 - val_accuracy: 0.9801\n",
      "Epoch 56/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1032 - accuracy: 0.9552 - val_loss: 0.0877 - val_accuracy: 0.9671\n",
      "Epoch 57/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1031 - accuracy: 0.9567 - val_loss: 0.0399 - val_accuracy: 0.9853\n",
      "Epoch 58/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1048 - accuracy: 0.9559 - val_loss: 0.0461 - val_accuracy: 0.9837\n",
      "Epoch 59/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1019 - accuracy: 0.9572 - val_loss: 0.0406 - val_accuracy: 0.9858\n",
      "Epoch 60/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1070 - accuracy: 0.9541 - val_loss: 0.0516 - val_accuracy: 0.9830\n",
      "Epoch 61/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1047 - accuracy: 0.9543 - val_loss: 0.0473 - val_accuracy: 0.9829\n",
      "Epoch 62/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1038 - accuracy: 0.9551 - val_loss: 0.0390 - val_accuracy: 0.9840\n",
      "Epoch 63/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1028 - accuracy: 0.9557 - val_loss: 0.1125 - val_accuracy: 0.9574\n",
      "Epoch 64/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1053 - accuracy: 0.9572 - val_loss: 0.1925 - val_accuracy: 0.9462\n",
      "Epoch 65/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1051 - accuracy: 0.9558 - val_loss: 0.0581 - val_accuracy: 0.9761\n",
      "Epoch 66/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1034 - accuracy: 0.9564 - val_loss: 0.0392 - val_accuracy: 0.9844\n",
      "Epoch 67/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1033 - accuracy: 0.9565 - val_loss: 0.0382 - val_accuracy: 0.9847\n",
      "Epoch 68/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1053 - accuracy: 0.9544 - val_loss: 0.0406 - val_accuracy: 0.9843\n",
      "Epoch 69/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1065 - accuracy: 0.9565 - val_loss: 0.0420 - val_accuracy: 0.9854\n",
      "Epoch 70/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1049 - accuracy: 0.9561 - val_loss: 0.0453 - val_accuracy: 0.9814\n",
      "Epoch 71/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1064 - accuracy: 0.9553 - val_loss: 0.0414 - val_accuracy: 0.9850\n",
      "Epoch 72/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1043 - accuracy: 0.9569 - val_loss: 0.0657 - val_accuracy: 0.9807\n",
      "Epoch 73/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1066 - accuracy: 0.9556 - val_loss: 0.0434 - val_accuracy: 0.9846\n",
      "Epoch 74/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1045 - accuracy: 0.9568 - val_loss: 0.0518 - val_accuracy: 0.9833\n",
      "Epoch 75/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.1007 - accuracy: 0.9561 - val_loss: 0.0417 - val_accuracy: 0.9840\n",
      "Epoch 76/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1025 - accuracy: 0.9567 - val_loss: 0.0860 - val_accuracy: 0.9750\n",
      "Epoch 77/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1038 - accuracy: 0.9563 - val_loss: 0.0394 - val_accuracy: 0.9863\n",
      "Epoch 78/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1058 - accuracy: 0.9567 - val_loss: 0.0539 - val_accuracy: 0.9817\n",
      "Epoch 79/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1028 - accuracy: 0.9570 - val_loss: 0.0383 - val_accuracy: 0.9859\n",
      "Epoch 80/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1057 - accuracy: 0.9579 - val_loss: 0.0536 - val_accuracy: 0.9782\n",
      "Epoch 81/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1050 - accuracy: 0.9569 - val_loss: 0.0568 - val_accuracy: 0.9824\n",
      "Epoch 82/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1035 - accuracy: 0.9555 - val_loss: 0.0402 - val_accuracy: 0.9843\n",
      "Epoch 83/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1046 - accuracy: 0.9565 - val_loss: 0.0466 - val_accuracy: 0.9843\n",
      "Epoch 84/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1006 - accuracy: 0.9562 - val_loss: 0.0711 - val_accuracy: 0.9679\n",
      "Epoch 85/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1051 - accuracy: 0.9569 - val_loss: 0.0460 - val_accuracy: 0.9821\n",
      "Epoch 86/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1039 - accuracy: 0.9554 - val_loss: 0.0416 - val_accuracy: 0.9841\n",
      "Epoch 87/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1039 - accuracy: 0.9567 - val_loss: 0.0391 - val_accuracy: 0.9852\n",
      "Epoch 88/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1041 - accuracy: 0.9548 - val_loss: 0.0374 - val_accuracy: 0.9862\n",
      "Epoch 89/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1031 - accuracy: 0.9561 - val_loss: 0.0647 - val_accuracy: 0.9714\n",
      "Epoch 90/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1080 - accuracy: 0.9545 - val_loss: 0.0381 - val_accuracy: 0.9852\n",
      "Epoch 91/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1008 - accuracy: 0.9576 - val_loss: 0.0389 - val_accuracy: 0.9854\n",
      "Epoch 92/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1014 - accuracy: 0.9579 - val_loss: 0.0482 - val_accuracy: 0.9821\n",
      "Epoch 93/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1025 - accuracy: 0.9571 - val_loss: 0.0859 - val_accuracy: 0.9604\n",
      "Epoch 94/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1028 - accuracy: 0.9577 - val_loss: 0.0486 - val_accuracy: 0.9823\n",
      "Epoch 95/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1029 - accuracy: 0.9579 - val_loss: 0.0537 - val_accuracy: 0.9863\n",
      "Epoch 96/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1059 - accuracy: 0.9557 - val_loss: 0.0388 - val_accuracy: 0.9860\n",
      "Epoch 97/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0998 - accuracy: 0.9574 - val_loss: 0.0572 - val_accuracy: 0.9806\n",
      "Epoch 98/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1046 - accuracy: 0.9558 - val_loss: 0.0382 - val_accuracy: 0.9863\n",
      "Epoch 99/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1032 - accuracy: 0.9563 - val_loss: 0.0551 - val_accuracy: 0.9827\n",
      "Epoch 100/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1028 - accuracy: 0.9571 - val_loss: 0.0505 - val_accuracy: 0.9829\n",
      "Epoch 101/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1019 - accuracy: 0.9577 - val_loss: 0.0414 - val_accuracy: 0.9850\n",
      "Epoch 102/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1018 - accuracy: 0.9566 - val_loss: 0.0515 - val_accuracy: 0.9795\n",
      "Epoch 103/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1021 - accuracy: 0.9565 - val_loss: 0.1235 - val_accuracy: 0.9604\n",
      "Epoch 104/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1042 - accuracy: 0.9564 - val_loss: 0.0529 - val_accuracy: 0.9834\n",
      "Epoch 105/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1035 - accuracy: 0.9556 - val_loss: 0.0474 - val_accuracy: 0.9809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.1006 - accuracy: 0.9569 - val_loss: 0.0453 - val_accuracy: 0.9859\n",
      "Epoch 107/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1028 - accuracy: 0.9587 - val_loss: 0.0433 - val_accuracy: 0.9816\n",
      "Epoch 108/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1022 - accuracy: 0.9563 - val_loss: 0.0597 - val_accuracy: 0.9741\n",
      "Epoch 109/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0997 - accuracy: 0.9584 - val_loss: 0.0524 - val_accuracy: 0.9811\n",
      "Epoch 110/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1027 - accuracy: 0.9571 - val_loss: 0.0423 - val_accuracy: 0.9840\n",
      "Epoch 111/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1021 - accuracy: 0.9578 - val_loss: 0.0615 - val_accuracy: 0.9756\n",
      "Epoch 112/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1012 - accuracy: 0.9573 - val_loss: 0.0445 - val_accuracy: 0.9823\n",
      "Epoch 113/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1013 - accuracy: 0.9573 - val_loss: 0.0414 - val_accuracy: 0.9833\n",
      "Epoch 114/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1019 - accuracy: 0.9564 - val_loss: 0.0576 - val_accuracy: 0.9836\n",
      "Epoch 115/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1053 - accuracy: 0.9557 - val_loss: 0.0422 - val_accuracy: 0.9837\n",
      "Epoch 116/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0995 - accuracy: 0.9577 - val_loss: 0.0485 - val_accuracy: 0.9811\n",
      "Epoch 117/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1021 - accuracy: 0.9573 - val_loss: 0.0410 - val_accuracy: 0.9841\n",
      "Epoch 118/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1007 - accuracy: 0.9593 - val_loss: 0.0450 - val_accuracy: 0.9843\n",
      "Epoch 119/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1020 - accuracy: 0.9582 - val_loss: 0.0426 - val_accuracy: 0.9850\n",
      "Epoch 120/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1002 - accuracy: 0.9584 - val_loss: 0.0637 - val_accuracy: 0.9837\n",
      "Epoch 121/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1011 - accuracy: 0.9572 - val_loss: 0.0393 - val_accuracy: 0.9835\n",
      "Epoch 122/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1017 - accuracy: 0.9572 - val_loss: 0.0431 - val_accuracy: 0.9835\n",
      "Epoch 123/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1024 - accuracy: 0.9577 - val_loss: 0.0394 - val_accuracy: 0.9845\n",
      "Epoch 124/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1020 - accuracy: 0.9566 - val_loss: 0.0533 - val_accuracy: 0.9833\n",
      "Epoch 125/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1038 - accuracy: 0.9565 - val_loss: 0.0458 - val_accuracy: 0.9847\n",
      "Epoch 126/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1026 - accuracy: 0.9589 - val_loss: 0.0464 - val_accuracy: 0.9841\n",
      "Epoch 127/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1029 - accuracy: 0.9579 - val_loss: 0.0496 - val_accuracy: 0.9834\n",
      "Epoch 128/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1013 - accuracy: 0.9572 - val_loss: 0.0363 - val_accuracy: 0.9856\n",
      "Epoch 129/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1011 - accuracy: 0.9588 - val_loss: 0.0400 - val_accuracy: 0.9837\n",
      "Epoch 130/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1003 - accuracy: 0.9588 - val_loss: 0.0365 - val_accuracy: 0.9868\n",
      "Epoch 131/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0992 - accuracy: 0.9583 - val_loss: 0.0407 - val_accuracy: 0.9834\n",
      "Epoch 132/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1010 - accuracy: 0.9578 - val_loss: 0.0398 - val_accuracy: 0.9854\n",
      "Epoch 133/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1008 - accuracy: 0.9580 - val_loss: 0.0382 - val_accuracy: 0.9856\n",
      "Epoch 134/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.0992 - accuracy: 0.9570 - val_loss: 0.0395 - val_accuracy: 0.9845\n",
      "Epoch 135/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0993 - accuracy: 0.9580 - val_loss: 0.0417 - val_accuracy: 0.9844\n",
      "Epoch 136/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1005 - accuracy: 0.9564 - val_loss: 0.0406 - val_accuracy: 0.9837\n",
      "Epoch 137/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1013 - accuracy: 0.9572 - val_loss: 0.0426 - val_accuracy: 0.9849\n",
      "Epoch 138/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1013 - accuracy: 0.9572 - val_loss: 0.0550 - val_accuracy: 0.9823\n",
      "Epoch 139/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1007 - accuracy: 0.9570 - val_loss: 0.0994 - val_accuracy: 0.9789\n",
      "Epoch 140/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0994 - accuracy: 0.9568 - val_loss: 0.0499 - val_accuracy: 0.9834\n",
      "Epoch 141/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0996 - accuracy: 0.9590 - val_loss: 0.0474 - val_accuracy: 0.9862\n",
      "Epoch 142/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1017 - accuracy: 0.9573 - val_loss: 0.0559 - val_accuracy: 0.9834\n",
      "Epoch 143/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1000 - accuracy: 0.9575 - val_loss: 0.0679 - val_accuracy: 0.9732\n",
      "Epoch 144/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.1005 - accuracy: 0.9572 - val_loss: 0.0741 - val_accuracy: 0.9676\n",
      "Epoch 145/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1003 - accuracy: 0.9581 - val_loss: 0.0430 - val_accuracy: 0.9848\n",
      "Epoch 146/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1003 - accuracy: 0.9578 - val_loss: 0.0636 - val_accuracy: 0.9732\n",
      "Epoch 147/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1012 - accuracy: 0.9570 - val_loss: 0.0404 - val_accuracy: 0.9857\n",
      "Epoch 148/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1009 - accuracy: 0.9575 - val_loss: 0.0480 - val_accuracy: 0.9868\n",
      "Epoch 149/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1016 - accuracy: 0.9572 - val_loss: 0.0380 - val_accuracy: 0.9840\n",
      "Epoch 150/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0976 - accuracy: 0.9592 - val_loss: 0.0401 - val_accuracy: 0.9845\n",
      "Epoch 151/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0981 - accuracy: 0.9597 - val_loss: 0.0551 - val_accuracy: 0.9837\n",
      "Epoch 152/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1007 - accuracy: 0.9586 - val_loss: 0.0443 - val_accuracy: 0.9837\n",
      "Epoch 153/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1007 - accuracy: 0.9579 - val_loss: 0.0767 - val_accuracy: 0.9683\n",
      "Epoch 154/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1011 - accuracy: 0.9582 - val_loss: 0.0506 - val_accuracy: 0.9760\n",
      "Epoch 155/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1017 - accuracy: 0.9570 - val_loss: 0.0380 - val_accuracy: 0.9861\n",
      "Epoch 156/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1009 - accuracy: 0.9572 - val_loss: 0.0466 - val_accuracy: 0.9824\n",
      "Epoch 157/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1011 - accuracy: 0.9579 - val_loss: 0.0537 - val_accuracy: 0.9820\n",
      "Epoch 158/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0994 - accuracy: 0.9568 - val_loss: 0.0369 - val_accuracy: 0.9855\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1007 - accuracy: 0.9579 - val_loss: 0.0542 - val_accuracy: 0.9829\n",
      "Epoch 160/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0989 - accuracy: 0.9601 - val_loss: 0.0375 - val_accuracy: 0.9854\n",
      "Epoch 161/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1015 - accuracy: 0.9589 - val_loss: 0.0463 - val_accuracy: 0.9866\n",
      "Epoch 162/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1022 - accuracy: 0.9571 - val_loss: 0.0886 - val_accuracy: 0.9616\n",
      "Epoch 163/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0982 - accuracy: 0.9580 - val_loss: 0.0916 - val_accuracy: 0.9791\n",
      "Epoch 164/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0988 - accuracy: 0.9585 - val_loss: 0.0382 - val_accuracy: 0.9852\n",
      "Epoch 165/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1005 - accuracy: 0.9593 - val_loss: 0.0439 - val_accuracy: 0.9863\n",
      "Epoch 166/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0994 - accuracy: 0.9570 - val_loss: 0.0370 - val_accuracy: 0.9858\n",
      "Epoch 167/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.1008 - accuracy: 0.9580 - val_loss: 0.0400 - val_accuracy: 0.9862\n",
      "Epoch 168/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0979 - accuracy: 0.9588 - val_loss: 0.0452 - val_accuracy: 0.9845\n",
      "Epoch 169/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0986 - accuracy: 0.9581 - val_loss: 0.0458 - val_accuracy: 0.9835\n",
      "Epoch 170/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0980 - accuracy: 0.9597 - val_loss: 0.0433 - val_accuracy: 0.9846\n",
      "Epoch 171/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0994 - accuracy: 0.9591 - val_loss: 0.0405 - val_accuracy: 0.9834\n",
      "Epoch 172/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0999 - accuracy: 0.9589 - val_loss: 0.0346 - val_accuracy: 0.9860\n",
      "Epoch 173/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0997 - accuracy: 0.9596 - val_loss: 0.0642 - val_accuracy: 0.9823\n",
      "Epoch 174/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0987 - accuracy: 0.9576 - val_loss: 0.0487 - val_accuracy: 0.9831\n",
      "Epoch 175/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0984 - accuracy: 0.9587 - val_loss: 0.0376 - val_accuracy: 0.9851\n",
      "Epoch 176/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0984 - accuracy: 0.9593 - val_loss: 0.0447 - val_accuracy: 0.9859\n",
      "Epoch 177/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1003 - accuracy: 0.9599 - val_loss: 0.0370 - val_accuracy: 0.9869\n",
      "Epoch 178/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0953 - accuracy: 0.9610 - val_loss: 0.0400 - val_accuracy: 0.9840\n",
      "Epoch 179/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0981 - accuracy: 0.9596 - val_loss: 0.0475 - val_accuracy: 0.9843\n",
      "Epoch 180/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0971 - accuracy: 0.9591 - val_loss: 0.0501 - val_accuracy: 0.9799\n",
      "Epoch 181/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0986 - accuracy: 0.9603 - val_loss: 0.0543 - val_accuracy: 0.9806\n",
      "Epoch 182/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0983 - accuracy: 0.9596 - val_loss: 0.0533 - val_accuracy: 0.9832\n",
      "Epoch 183/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0969 - accuracy: 0.9599 - val_loss: 0.0350 - val_accuracy: 0.9865\n",
      "Epoch 184/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0968 - accuracy: 0.9604 - val_loss: 0.0809 - val_accuracy: 0.9851\n",
      "Epoch 185/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0975 - accuracy: 0.9590 - val_loss: 0.0380 - val_accuracy: 0.9862\n",
      "Epoch 186/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0990 - accuracy: 0.9590 - val_loss: 0.0673 - val_accuracy: 0.9828\n",
      "Epoch 187/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0976 - accuracy: 0.9592 - val_loss: 0.0407 - val_accuracy: 0.9850\n",
      "Epoch 188/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0949 - accuracy: 0.9608 - val_loss: 0.0367 - val_accuracy: 0.9856\n",
      "Epoch 189/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0991 - accuracy: 0.9609 - val_loss: 0.0391 - val_accuracy: 0.9850\n",
      "Epoch 190/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0988 - accuracy: 0.9593 - val_loss: 0.0479 - val_accuracy: 0.9836\n",
      "Epoch 191/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0996 - accuracy: 0.9596 - val_loss: 0.0654 - val_accuracy: 0.9866\n",
      "Epoch 192/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0984 - accuracy: 0.9597 - val_loss: 0.0664 - val_accuracy: 0.9776\n",
      "Epoch 193/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0984 - accuracy: 0.9604 - val_loss: 0.0621 - val_accuracy: 0.9714\n",
      "Epoch 194/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0957 - accuracy: 0.9592 - val_loss: 0.0368 - val_accuracy: 0.9864\n",
      "Epoch 195/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0953 - accuracy: 0.9613 - val_loss: 0.0361 - val_accuracy: 0.9856\n",
      "Epoch 196/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0989 - accuracy: 0.9606 - val_loss: 0.0454 - val_accuracy: 0.9847\n",
      "Epoch 197/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0953 - accuracy: 0.9604 - val_loss: 0.0452 - val_accuracy: 0.9855\n",
      "Epoch 198/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0945 - accuracy: 0.9593 - val_loss: 0.0624 - val_accuracy: 0.9795\n",
      "Epoch 199/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0964 - accuracy: 0.9604 - val_loss: 0.0390 - val_accuracy: 0.9848\n",
      "Epoch 200/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0983 - accuracy: 0.9599 - val_loss: 0.1098 - val_accuracy: 0.9530\n",
      "Epoch 201/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0988 - accuracy: 0.9592 - val_loss: 0.0493 - val_accuracy: 0.9867\n",
      "Epoch 202/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0985 - accuracy: 0.9602 - val_loss: 0.0453 - val_accuracy: 0.9870\n",
      "Epoch 203/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0983 - accuracy: 0.9600 - val_loss: 0.0395 - val_accuracy: 0.9835\n",
      "Epoch 204/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0949 - accuracy: 0.9608 - val_loss: 0.0348 - val_accuracy: 0.9870\n",
      "Epoch 205/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0954 - accuracy: 0.9596 - val_loss: 0.0413 - val_accuracy: 0.9868\n",
      "Epoch 206/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1000 - accuracy: 0.9593 - val_loss: 0.0403 - val_accuracy: 0.9834\n",
      "Epoch 207/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1003 - accuracy: 0.9598 - val_loss: 0.0601 - val_accuracy: 0.9792\n",
      "Epoch 208/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0957 - accuracy: 0.9596 - val_loss: 0.0444 - val_accuracy: 0.9844\n",
      "Epoch 209/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0939 - accuracy: 0.9619 - val_loss: 0.0494 - val_accuracy: 0.9841\n",
      "Epoch 210/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1147 - accuracy: 0.9581 - val_loss: 0.0478 - val_accuracy: 0.9851\n",
      "Epoch 211/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0970 - accuracy: 0.9590 - val_loss: 0.0399 - val_accuracy: 0.9866\n",
      "Epoch 212/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0937 - accuracy: 0.9607 - val_loss: 0.0436 - val_accuracy: 0.9830\n",
      "Epoch 213/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0963 - accuracy: 0.9601 - val_loss: 0.0579 - val_accuracy: 0.9793\n",
      "Epoch 214/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0950 - accuracy: 0.9605 - val_loss: 0.0466 - val_accuracy: 0.9872\n",
      "Epoch 215/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0958 - accuracy: 0.9605 - val_loss: 0.0831 - val_accuracy: 0.9733\n",
      "Epoch 216/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0952 - accuracy: 0.9604 - val_loss: 0.0391 - val_accuracy: 0.9840\n",
      "Epoch 217/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0960 - accuracy: 0.9611 - val_loss: 0.0425 - val_accuracy: 0.9838\n",
      "Epoch 218/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0950 - accuracy: 0.9606 - val_loss: 0.0591 - val_accuracy: 0.9802\n",
      "Epoch 219/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0944 - accuracy: 0.9602 - val_loss: 0.0377 - val_accuracy: 0.9845\n",
      "Epoch 220/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0949 - accuracy: 0.9601 - val_loss: 0.0581 - val_accuracy: 0.9812\n",
      "Epoch 221/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0981 - accuracy: 0.9594 - val_loss: 0.0640 - val_accuracy: 0.9737\n",
      "Epoch 222/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0960 - accuracy: 0.9597 - val_loss: 0.0550 - val_accuracy: 0.9840\n",
      "Epoch 223/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0951 - accuracy: 0.9600 - val_loss: 0.0370 - val_accuracy: 0.9849\n",
      "Epoch 224/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0954 - accuracy: 0.9612 - val_loss: 0.0866 - val_accuracy: 0.9806\n",
      "Epoch 225/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0960 - accuracy: 0.9613 - val_loss: 0.0398 - val_accuracy: 0.9853\n",
      "Epoch 226/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0964 - accuracy: 0.9606 - val_loss: 0.0623 - val_accuracy: 0.9830\n",
      "Epoch 227/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0980 - accuracy: 0.9613 - val_loss: 0.0422 - val_accuracy: 0.9838\n",
      "Epoch 228/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0964 - accuracy: 0.9615 - val_loss: 0.0384 - val_accuracy: 0.9842\n",
      "Epoch 229/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0963 - accuracy: 0.9598 - val_loss: 0.0500 - val_accuracy: 0.9824\n",
      "Epoch 230/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0936 - accuracy: 0.9598 - val_loss: 0.0435 - val_accuracy: 0.9838\n",
      "Epoch 231/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0931 - accuracy: 0.9607 - val_loss: 0.0472 - val_accuracy: 0.9870\n",
      "Epoch 232/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1075 - accuracy: 0.9610 - val_loss: 0.0520 - val_accuracy: 0.9831\n",
      "Epoch 233/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1075 - accuracy: 0.9592 - val_loss: 0.0363 - val_accuracy: 0.9858\n",
      "Epoch 234/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0968 - accuracy: 0.9604 - val_loss: 0.0369 - val_accuracy: 0.9851\n",
      "Epoch 235/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1084 - accuracy: 0.9594 - val_loss: 0.0392 - val_accuracy: 0.9847\n",
      "Epoch 236/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0940 - accuracy: 0.9603 - val_loss: 0.0471 - val_accuracy: 0.9838\n",
      "Epoch 237/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0985 - accuracy: 0.9598 - val_loss: 0.0482 - val_accuracy: 0.9802\n",
      "Epoch 238/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0923 - accuracy: 0.9604 - val_loss: 0.0388 - val_accuracy: 0.9856\n",
      "Epoch 239/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0948 - accuracy: 0.9617 - val_loss: 0.0651 - val_accuracy: 0.9781\n",
      "Epoch 240/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0930 - accuracy: 0.9608 - val_loss: 0.0504 - val_accuracy: 0.9800\n",
      "Epoch 241/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0944 - accuracy: 0.9604 - val_loss: 0.0559 - val_accuracy: 0.9785\n",
      "Epoch 242/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0942 - accuracy: 0.9590 - val_loss: 0.0461 - val_accuracy: 0.9850\n",
      "Epoch 243/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0950 - accuracy: 0.9601 - val_loss: 0.0451 - val_accuracy: 0.9808\n",
      "Epoch 244/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0955 - accuracy: 0.9603 - val_loss: 0.0430 - val_accuracy: 0.9844\n",
      "Epoch 245/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0966 - accuracy: 0.9603 - val_loss: 0.0439 - val_accuracy: 0.9844\n",
      "Epoch 246/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0940 - accuracy: 0.9613 - val_loss: 0.0420 - val_accuracy: 0.9864\n",
      "Epoch 247/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0927 - accuracy: 0.9605 - val_loss: 0.0504 - val_accuracy: 0.9805\n",
      "Epoch 248/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0951 - accuracy: 0.9609 - val_loss: 0.0433 - val_accuracy: 0.9866\n",
      "Epoch 249/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0943 - accuracy: 0.9611 - val_loss: 0.0384 - val_accuracy: 0.9818\n",
      "Epoch 250/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0938 - accuracy: 0.9613 - val_loss: 0.0368 - val_accuracy: 0.9844\n",
      "Epoch 251/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0944 - accuracy: 0.9612 - val_loss: 0.0396 - val_accuracy: 0.9833\n",
      "Epoch 252/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0945 - accuracy: 0.9607 - val_loss: 0.0404 - val_accuracy: 0.9837\n",
      "Epoch 253/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0939 - accuracy: 0.9614 - val_loss: 0.0437 - val_accuracy: 0.9826\n",
      "Epoch 254/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0933 - accuracy: 0.9606 - val_loss: 0.0574 - val_accuracy: 0.9789\n",
      "Epoch 255/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0923 - accuracy: 0.9609 - val_loss: 0.0365 - val_accuracy: 0.9853\n",
      "Epoch 256/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0947 - accuracy: 0.9616 - val_loss: 0.0390 - val_accuracy: 0.9861\n",
      "Epoch 257/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0934 - accuracy: 0.9617 - val_loss: 0.0417 - val_accuracy: 0.9863\n",
      "Epoch 258/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0942 - accuracy: 0.9607 - val_loss: 0.0428 - val_accuracy: 0.9824\n",
      "Epoch 259/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0951 - accuracy: 0.9604 - val_loss: 0.0510 - val_accuracy: 0.9810\n",
      "Epoch 260/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0938 - accuracy: 0.9616 - val_loss: 0.0431 - val_accuracy: 0.9837\n",
      "Epoch 261/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0993 - accuracy: 0.9612 - val_loss: 0.0475 - val_accuracy: 0.9848\n",
      "Epoch 262/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0936 - accuracy: 0.9621 - val_loss: 0.0625 - val_accuracy: 0.9779\n",
      "Epoch 263/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0941 - accuracy: 0.9590 - val_loss: 0.0498 - val_accuracy: 0.9821\n",
      "Epoch 264/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.9620 - val_loss: 0.0481 - val_accuracy: 0.9788\n",
      "Epoch 265/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0927 - accuracy: 0.9615 - val_loss: 0.0397 - val_accuracy: 0.9840\n",
      "Epoch 266/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0919 - accuracy: 0.9604 - val_loss: 0.0505 - val_accuracy: 0.9824\n",
      "Epoch 267/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0927 - accuracy: 0.9615 - val_loss: 0.0424 - val_accuracy: 0.9865\n",
      "Epoch 268/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0947 - accuracy: 0.9615 - val_loss: 0.1524 - val_accuracy: 0.9506\n",
      "Epoch 269/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0959 - accuracy: 0.9584 - val_loss: 0.0369 - val_accuracy: 0.9849\n",
      "Epoch 270/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0971 - accuracy: 0.9607 - val_loss: 0.0661 - val_accuracy: 0.9832\n",
      "Epoch 271/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0940 - accuracy: 0.9616 - val_loss: 0.0778 - val_accuracy: 0.9665\n",
      "Epoch 272/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0972 - accuracy: 0.9605 - val_loss: 0.0401 - val_accuracy: 0.9834\n",
      "Epoch 273/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0937 - accuracy: 0.9609 - val_loss: 0.0468 - val_accuracy: 0.9825\n",
      "Epoch 274/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0905 - accuracy: 0.9630 - val_loss: 0.0394 - val_accuracy: 0.9846\n",
      "Epoch 275/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0934 - accuracy: 0.9603 - val_loss: 0.0423 - val_accuracy: 0.9820\n",
      "Epoch 276/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1145 - accuracy: 0.9609 - val_loss: 0.0419 - val_accuracy: 0.9834\n",
      "Epoch 277/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1143 - accuracy: 0.9597 - val_loss: 0.0508 - val_accuracy: 0.9799\n",
      "Epoch 278/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0935 - accuracy: 0.9624 - val_loss: 0.0394 - val_accuracy: 0.9859\n",
      "Epoch 279/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0926 - accuracy: 0.9620 - val_loss: 0.0453 - val_accuracy: 0.9845\n",
      "Epoch 280/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0932 - accuracy: 0.9627 - val_loss: 0.0823 - val_accuracy: 0.9714\n",
      "Epoch 281/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0937 - accuracy: 0.9619 - val_loss: 0.0410 - val_accuracy: 0.9850\n",
      "Epoch 282/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0939 - accuracy: 0.9603 - val_loss: 0.0396 - val_accuracy: 0.9856\n",
      "Epoch 283/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0900 - accuracy: 0.9629 - val_loss: 0.0383 - val_accuracy: 0.9878\n",
      "Epoch 284/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0929 - accuracy: 0.9628 - val_loss: 0.0388 - val_accuracy: 0.9853\n",
      "Epoch 285/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0934 - accuracy: 0.9632 - val_loss: 0.0405 - val_accuracy: 0.9830\n",
      "Epoch 286/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0943 - accuracy: 0.9606 - val_loss: 0.0476 - val_accuracy: 0.9823\n",
      "Epoch 287/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0967 - accuracy: 0.9616 - val_loss: 0.0432 - val_accuracy: 0.9803\n",
      "Epoch 288/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0905 - accuracy: 0.9608 - val_loss: 0.0380 - val_accuracy: 0.9850\n",
      "Epoch 289/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.0927 - accuracy: 0.9612 - val_loss: 0.0377 - val_accuracy: 0.9841\n",
      "Epoch 290/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0943 - accuracy: 0.9611 - val_loss: 0.0523 - val_accuracy: 0.9808\n",
      "Epoch 291/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0934 - accuracy: 0.9606 - val_loss: 0.0364 - val_accuracy: 0.9863\n",
      "Epoch 292/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0953 - accuracy: 0.9604 - val_loss: 0.0371 - val_accuracy: 0.9840\n",
      "Epoch 293/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0938 - accuracy: 0.9611 - val_loss: 0.0383 - val_accuracy: 0.9850\n",
      "Epoch 294/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0946 - accuracy: 0.9622 - val_loss: 0.0376 - val_accuracy: 0.9853\n",
      "Epoch 295/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0926 - accuracy: 0.9616 - val_loss: 0.0447 - val_accuracy: 0.9844\n",
      "Epoch 296/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0935 - accuracy: 0.9618 - val_loss: 0.0988 - val_accuracy: 0.9651\n",
      "Epoch 297/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0960 - accuracy: 0.9616 - val_loss: 0.0421 - val_accuracy: 0.9806\n",
      "Epoch 298/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0925 - accuracy: 0.9622 - val_loss: 0.0451 - val_accuracy: 0.9830\n",
      "Epoch 299/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0936 - accuracy: 0.9616 - val_loss: 0.0634 - val_accuracy: 0.9794\n",
      "Epoch 300/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0942 - accuracy: 0.9615 - val_loss: 0.0376 - val_accuracy: 0.9827\n",
      "Epoch 301/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0922 - accuracy: 0.9610 - val_loss: 0.0462 - val_accuracy: 0.9849\n",
      "Epoch 302/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0957 - accuracy: 0.9617 - val_loss: 0.0437 - val_accuracy: 0.9825\n",
      "Epoch 303/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0923 - accuracy: 0.9614 - val_loss: 0.0423 - val_accuracy: 0.9854\n",
      "Epoch 304/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0927 - accuracy: 0.9613 - val_loss: 0.0379 - val_accuracy: 0.9863\n",
      "Epoch 305/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0937 - accuracy: 0.9622 - val_loss: 0.0481 - val_accuracy: 0.9791\n",
      "Epoch 306/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0935 - accuracy: 0.9617 - val_loss: 0.0521 - val_accuracy: 0.9820\n",
      "Epoch 307/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0934 - accuracy: 0.9624 - val_loss: 0.0493 - val_accuracy: 0.9808\n",
      "Epoch 308/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0921 - accuracy: 0.9623 - val_loss: 0.0609 - val_accuracy: 0.9814\n",
      "Epoch 309/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0915 - accuracy: 0.9612 - val_loss: 0.0416 - val_accuracy: 0.9837\n",
      "Epoch 310/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0935 - accuracy: 0.9621 - val_loss: 0.0469 - val_accuracy: 0.9828\n",
      "Epoch 311/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0925 - accuracy: 0.9624 - val_loss: 0.0505 - val_accuracy: 0.9849\n",
      "Epoch 312/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0940 - accuracy: 0.9623 - val_loss: 0.0345 - val_accuracy: 0.9870\n",
      "Epoch 313/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0923 - accuracy: 0.9605 - val_loss: 0.0460 - val_accuracy: 0.9831\n",
      "Epoch 314/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9623 - val_loss: 0.0419 - val_accuracy: 0.9830\n",
      "Epoch 315/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0968 - accuracy: 0.9610 - val_loss: 0.0505 - val_accuracy: 0.9825\n",
      "Epoch 316/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1213 - accuracy: 0.9605 - val_loss: 0.0458 - val_accuracy: 0.9854\n",
      "Epoch 317/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0932 - accuracy: 0.9607 - val_loss: 0.0416 - val_accuracy: 0.9834\n",
      "Epoch 318/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0940 - accuracy: 0.9624 - val_loss: 0.0590 - val_accuracy: 0.9754\n",
      "Epoch 319/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0949 - accuracy: 0.9592 - val_loss: 0.0427 - val_accuracy: 0.9874\n",
      "Epoch 320/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0945 - accuracy: 0.9623 - val_loss: 0.0355 - val_accuracy: 0.9872\n",
      "Epoch 321/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0918 - accuracy: 0.9621 - val_loss: 0.0376 - val_accuracy: 0.9849\n",
      "Epoch 322/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0946 - accuracy: 0.9604 - val_loss: 0.0360 - val_accuracy: 0.9863\n",
      "Epoch 323/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0933 - accuracy: 0.9618 - val_loss: 0.0449 - val_accuracy: 0.9834\n",
      "Epoch 324/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0933 - accuracy: 0.9622 - val_loss: 0.0519 - val_accuracy: 0.9817\n",
      "Epoch 325/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0946 - accuracy: 0.9607 - val_loss: 0.0802 - val_accuracy: 0.9766\n",
      "Epoch 326/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0938 - accuracy: 0.9612 - val_loss: 0.0425 - val_accuracy: 0.9849\n",
      "Epoch 327/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0926 - accuracy: 0.9612 - val_loss: 0.0444 - val_accuracy: 0.9860\n",
      "Epoch 328/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0941 - accuracy: 0.9618 - val_loss: 0.0427 - val_accuracy: 0.9821\n",
      "Epoch 329/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0916 - accuracy: 0.9621 - val_loss: 0.0482 - val_accuracy: 0.9813\n",
      "Epoch 330/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0930 - accuracy: 0.9619 - val_loss: 0.0376 - val_accuracy: 0.9849\n",
      "Epoch 331/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1320 - accuracy: 0.9578 - val_loss: 0.0393 - val_accuracy: 0.9834\n",
      "Epoch 332/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0906 - accuracy: 0.9623 - val_loss: 0.0412 - val_accuracy: 0.9847\n",
      "Epoch 333/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0885 - accuracy: 0.9628 - val_loss: 0.0490 - val_accuracy: 0.9851\n",
      "Epoch 334/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0927 - accuracy: 0.9618 - val_loss: 0.0600 - val_accuracy: 0.9803\n",
      "Epoch 335/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9618 - val_loss: 0.0453 - val_accuracy: 0.9837\n",
      "Epoch 336/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0922 - accuracy: 0.9630 - val_loss: 0.0670 - val_accuracy: 0.9841\n",
      "Epoch 337/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0908 - accuracy: 0.9607 - val_loss: 0.0397 - val_accuracy: 0.9854\n",
      "Epoch 338/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0970 - accuracy: 0.9607 - val_loss: 0.0572 - val_accuracy: 0.9798\n",
      "Epoch 339/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0941 - accuracy: 0.9609 - val_loss: 0.0756 - val_accuracy: 0.9662\n",
      "Epoch 340/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0916 - accuracy: 0.9611 - val_loss: 0.0480 - val_accuracy: 0.9854\n",
      "Epoch 341/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0914 - accuracy: 0.9637 - val_loss: 0.0384 - val_accuracy: 0.9853\n",
      "Epoch 342/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0923 - accuracy: 0.9624 - val_loss: 0.0531 - val_accuracy: 0.9779\n",
      "Epoch 343/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0910 - accuracy: 0.9627 - val_loss: 0.0487 - val_accuracy: 0.9805\n",
      "Epoch 344/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9620 - val_loss: 0.0400 - val_accuracy: 0.9836\n",
      "Epoch 345/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0915 - accuracy: 0.9624 - val_loss: 0.0520 - val_accuracy: 0.9845\n",
      "Epoch 346/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0930 - accuracy: 0.9603 - val_loss: 0.0405 - val_accuracy: 0.9856\n",
      "Epoch 347/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0922 - accuracy: 0.9612 - val_loss: 0.0470 - val_accuracy: 0.9829\n",
      "Epoch 348/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.9618 - val_loss: 0.0401 - val_accuracy: 0.9855\n",
      "Epoch 349/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0925 - accuracy: 0.9608 - val_loss: 0.0638 - val_accuracy: 0.9743\n",
      "Epoch 350/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0904 - accuracy: 0.9627 - val_loss: 0.0354 - val_accuracy: 0.9859\n",
      "Epoch 351/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0919 - accuracy: 0.9622 - val_loss: 0.0377 - val_accuracy: 0.9855\n",
      "Epoch 352/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0929 - accuracy: 0.9613 - val_loss: 0.0440 - val_accuracy: 0.9832\n",
      "Epoch 353/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0928 - accuracy: 0.9614 - val_loss: 0.0413 - val_accuracy: 0.9838\n",
      "Epoch 354/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0902 - accuracy: 0.9618 - val_loss: 0.0491 - val_accuracy: 0.9843\n",
      "Epoch 355/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0938 - accuracy: 0.9621 - val_loss: 0.0411 - val_accuracy: 0.9852\n",
      "Epoch 356/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0925 - accuracy: 0.9612 - val_loss: 0.0686 - val_accuracy: 0.9840\n",
      "Epoch 357/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0933 - accuracy: 0.9635 - val_loss: 0.0400 - val_accuracy: 0.9838\n",
      "Epoch 358/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0910 - accuracy: 0.9620 - val_loss: 0.0752 - val_accuracy: 0.9782\n",
      "Epoch 359/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0940 - accuracy: 0.9614 - val_loss: 0.0449 - val_accuracy: 0.9847\n",
      "Epoch 360/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0921 - accuracy: 0.9632 - val_loss: 0.0926 - val_accuracy: 0.9704\n",
      "Epoch 361/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0938 - accuracy: 0.9611 - val_loss: 0.0520 - val_accuracy: 0.9766\n",
      "Epoch 362/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0942 - accuracy: 0.9616 - val_loss: 0.0362 - val_accuracy: 0.9856\n",
      "Epoch 363/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0900 - accuracy: 0.9627 - val_loss: 0.0439 - val_accuracy: 0.9864\n",
      "Epoch 364/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0916 - accuracy: 0.9616 - val_loss: 0.0482 - val_accuracy: 0.9838\n",
      "Epoch 365/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0918 - accuracy: 0.9626 - val_loss: 0.0404 - val_accuracy: 0.9854\n",
      "Epoch 366/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0897 - accuracy: 0.9635 - val_loss: 0.0421 - val_accuracy: 0.9859\n",
      "Epoch 367/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0985 - accuracy: 0.9608 - val_loss: 0.0411 - val_accuracy: 0.9847\n",
      "Epoch 368/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0934 - accuracy: 0.9612 - val_loss: 0.0403 - val_accuracy: 0.9830\n",
      "Epoch 369/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0929 - accuracy: 0.9620 - val_loss: 0.1086 - val_accuracy: 0.9577\n",
      "Epoch 370/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0918 - accuracy: 0.9623 - val_loss: 0.0418 - val_accuracy: 0.9842\n",
      "Epoch 371/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0913 - accuracy: 0.9613 - val_loss: 0.0537 - val_accuracy: 0.9818\n",
      "Epoch 372/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0934 - accuracy: 0.9613 - val_loss: 0.0394 - val_accuracy: 0.9852\n",
      "Epoch 373/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0906 - accuracy: 0.9628 - val_loss: 0.0409 - val_accuracy: 0.9863\n",
      "Epoch 374/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0931 - accuracy: 0.9618 - val_loss: 0.0488 - val_accuracy: 0.9814\n",
      "Epoch 375/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0914 - accuracy: 0.9595 - val_loss: 0.0456 - val_accuracy: 0.9832\n",
      "Epoch 376/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0953 - accuracy: 0.9618 - val_loss: 0.0359 - val_accuracy: 0.9865\n",
      "Epoch 377/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0953 - accuracy: 0.9614 - val_loss: 0.0374 - val_accuracy: 0.9832\n",
      "Epoch 378/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0942 - accuracy: 0.9619 - val_loss: 0.0436 - val_accuracy: 0.9814\n",
      "Epoch 379/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0915 - accuracy: 0.9620 - val_loss: 0.0531 - val_accuracy: 0.9823\n",
      "Epoch 380/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0911 - accuracy: 0.9621 - val_loss: 0.0514 - val_accuracy: 0.9804\n",
      "Epoch 381/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0910 - accuracy: 0.9631 - val_loss: 0.0446 - val_accuracy: 0.9841\n",
      "Epoch 382/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0911 - accuracy: 0.9633 - val_loss: 0.0403 - val_accuracy: 0.9849\n",
      "Epoch 383/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0934 - accuracy: 0.9613 - val_loss: 0.0457 - val_accuracy: 0.9808\n",
      "Epoch 384/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0932 - accuracy: 0.9620 - val_loss: 0.0459 - val_accuracy: 0.9818\n",
      "Epoch 385/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0953 - accuracy: 0.9606 - val_loss: 0.0414 - val_accuracy: 0.9836\n",
      "Epoch 386/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0917 - accuracy: 0.9620 - val_loss: 0.0408 - val_accuracy: 0.9846\n",
      "Epoch 387/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0914 - accuracy: 0.9617 - val_loss: 0.0524 - val_accuracy: 0.9839\n",
      "Epoch 388/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0920 - accuracy: 0.9618 - val_loss: 0.0458 - val_accuracy: 0.9827\n",
      "Epoch 389/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0916 - accuracy: 0.9620 - val_loss: 0.0550 - val_accuracy: 0.9781\n",
      "Epoch 390/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0916 - accuracy: 0.9627 - val_loss: 0.0381 - val_accuracy: 0.9856\n",
      "Epoch 391/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0916 - accuracy: 0.9622 - val_loss: 0.0720 - val_accuracy: 0.9859\n",
      "Epoch 392/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0936 - accuracy: 0.9624 - val_loss: 0.0405 - val_accuracy: 0.9845\n",
      "Epoch 393/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0933 - accuracy: 0.9608 - val_loss: 0.0479 - val_accuracy: 0.9839\n",
      "Epoch 394/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0916 - accuracy: 0.9633 - val_loss: 0.0394 - val_accuracy: 0.9867\n",
      "Epoch 395/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0901 - accuracy: 0.9632 - val_loss: 0.0426 - val_accuracy: 0.9822\n",
      "Epoch 396/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0899 - accuracy: 0.9623 - val_loss: 0.0517 - val_accuracy: 0.9828\n",
      "Epoch 397/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0911 - accuracy: 0.9627 - val_loss: 0.0853 - val_accuracy: 0.9734\n",
      "Epoch 398/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0921 - accuracy: 0.9605 - val_loss: 0.0463 - val_accuracy: 0.9837\n",
      "Epoch 399/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0927 - accuracy: 0.9622 - val_loss: 0.0455 - val_accuracy: 0.9814\n",
      "Epoch 400/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.9617 - val_loss: 0.0517 - val_accuracy: 0.9824\n",
      "Epoch 401/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0921 - accuracy: 0.9620 - val_loss: 0.0735 - val_accuracy: 0.9704\n",
      "Epoch 402/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0953 - accuracy: 0.9610 - val_loss: 0.0627 - val_accuracy: 0.9757\n",
      "Epoch 403/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0927 - accuracy: 0.9602 - val_loss: 0.0463 - val_accuracy: 0.9864\n",
      "Epoch 404/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0934 - accuracy: 0.9626 - val_loss: 0.0643 - val_accuracy: 0.9756\n",
      "Epoch 405/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0926 - accuracy: 0.9607 - val_loss: 0.0365 - val_accuracy: 0.9847\n",
      "Epoch 406/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0923 - accuracy: 0.9607 - val_loss: 0.0472 - val_accuracy: 0.9801\n",
      "Epoch 407/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0929 - accuracy: 0.9612 - val_loss: 0.0521 - val_accuracy: 0.9813\n",
      "Epoch 408/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0934 - accuracy: 0.9603 - val_loss: 0.0684 - val_accuracy: 0.9841\n",
      "Epoch 409/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0913 - accuracy: 0.9619 - val_loss: 0.0991 - val_accuracy: 0.9831\n",
      "Epoch 410/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0928 - accuracy: 0.9626 - val_loss: 0.0729 - val_accuracy: 0.9794\n",
      "Epoch 411/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0943 - accuracy: 0.9625 - val_loss: 0.0478 - val_accuracy: 0.9832\n",
      "Epoch 412/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0910 - accuracy: 0.9627 - val_loss: 0.0485 - val_accuracy: 0.9840\n",
      "Epoch 413/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9628 - val_loss: 0.0655 - val_accuracy: 0.9798\n",
      "Epoch 414/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0969 - accuracy: 0.9618 - val_loss: 0.0490 - val_accuracy: 0.9840\n",
      "Epoch 415/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0922 - accuracy: 0.9616 - val_loss: 0.0392 - val_accuracy: 0.9846\n",
      "Epoch 416/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0893 - accuracy: 0.9617 - val_loss: 0.0428 - val_accuracy: 0.9844\n",
      "Epoch 417/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0952 - accuracy: 0.9616 - val_loss: 0.0472 - val_accuracy: 0.9835\n",
      "Epoch 418/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0925 - accuracy: 0.9615 - val_loss: 0.0413 - val_accuracy: 0.9817\n",
      "Epoch 419/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0906 - accuracy: 0.9621 - val_loss: 0.0441 - val_accuracy: 0.9830\n",
      "Epoch 420/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0922 - accuracy: 0.9618 - val_loss: 0.0468 - val_accuracy: 0.9805\n",
      "Epoch 421/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0928 - accuracy: 0.9609 - val_loss: 0.0420 - val_accuracy: 0.9837\n",
      "Epoch 422/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0899 - accuracy: 0.9622 - val_loss: 0.0422 - val_accuracy: 0.9854\n",
      "Epoch 423/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0915 - accuracy: 0.9620 - val_loss: 0.0400 - val_accuracy: 0.9848\n",
      "Epoch 424/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0944 - accuracy: 0.9623 - val_loss: 0.0506 - val_accuracy: 0.9856\n",
      "Epoch 425/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0935 - accuracy: 0.9620 - val_loss: 0.0427 - val_accuracy: 0.9818\n",
      "Epoch 426/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0905 - accuracy: 0.9625 - val_loss: 0.0698 - val_accuracy: 0.9838\n",
      "Epoch 427/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.9604 - val_loss: 0.0454 - val_accuracy: 0.9840\n",
      "Epoch 428/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0925 - accuracy: 0.9617 - val_loss: 0.0453 - val_accuracy: 0.9846\n",
      "Epoch 429/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0928 - accuracy: 0.9629 - val_loss: 0.0409 - val_accuracy: 0.9849\n",
      "Epoch 430/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0905 - accuracy: 0.9624 - val_loss: 0.0403 - val_accuracy: 0.9872\n",
      "Epoch 431/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0908 - accuracy: 0.9619 - val_loss: 0.0501 - val_accuracy: 0.9812\n",
      "Epoch 432/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0913 - accuracy: 0.9623 - val_loss: 0.0447 - val_accuracy: 0.9823\n",
      "Epoch 433/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0912 - accuracy: 0.9637 - val_loss: 0.0382 - val_accuracy: 0.9853\n",
      "Epoch 434/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0910 - accuracy: 0.9626 - val_loss: 0.0529 - val_accuracy: 0.9808\n",
      "Epoch 435/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0951 - accuracy: 0.9620 - val_loss: 0.0534 - val_accuracy: 0.9834\n",
      "Epoch 436/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0925 - accuracy: 0.9613 - val_loss: 0.0439 - val_accuracy: 0.9835\n",
      "Epoch 437/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0928 - accuracy: 0.9616 - val_loss: 0.0486 - val_accuracy: 0.9811\n",
      "Epoch 438/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0908 - accuracy: 0.9627 - val_loss: 0.0487 - val_accuracy: 0.9855\n",
      "Epoch 439/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0921 - accuracy: 0.9610 - val_loss: 0.0496 - val_accuracy: 0.9804\n",
      "Epoch 440/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.9627 - val_loss: 0.0396 - val_accuracy: 0.9831\n",
      "Epoch 441/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0914 - accuracy: 0.9613 - val_loss: 0.0497 - val_accuracy: 0.9808\n",
      "Epoch 442/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0925 - accuracy: 0.9631 - val_loss: 0.0482 - val_accuracy: 0.9816\n",
      "Epoch 443/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1237 - accuracy: 0.9592 - val_loss: 0.0450 - val_accuracy: 0.9834\n",
      "Epoch 444/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9616 - val_loss: 0.0414 - val_accuracy: 0.9861\n",
      "Epoch 445/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.9607 - val_loss: 0.0477 - val_accuracy: 0.9829\n",
      "Epoch 446/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0911 - accuracy: 0.9623 - val_loss: 0.0493 - val_accuracy: 0.9839\n",
      "Epoch 447/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0914 - accuracy: 0.9629 - val_loss: 0.0455 - val_accuracy: 0.9853\n",
      "Epoch 448/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0926 - accuracy: 0.9624 - val_loss: 0.0468 - val_accuracy: 0.9844\n",
      "Epoch 449/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0907 - accuracy: 0.9620 - val_loss: 0.0409 - val_accuracy: 0.9830\n",
      "Epoch 450/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0958 - accuracy: 0.9616 - val_loss: 0.0391 - val_accuracy: 0.9859\n",
      "Epoch 451/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0891 - accuracy: 0.9628 - val_loss: 0.0619 - val_accuracy: 0.9733\n",
      "Epoch 452/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0920 - accuracy: 0.9625 - val_loss: 0.0630 - val_accuracy: 0.9817\n",
      "Epoch 453/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0914 - accuracy: 0.9618 - val_loss: 0.0387 - val_accuracy: 0.9853\n",
      "Epoch 454/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0894 - accuracy: 0.9629 - val_loss: 0.0415 - val_accuracy: 0.9840\n",
      "Epoch 455/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0906 - accuracy: 0.9627 - val_loss: 0.1095 - val_accuracy: 0.9747\n",
      "Epoch 456/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0958 - accuracy: 0.9624 - val_loss: 0.0432 - val_accuracy: 0.9865\n",
      "Epoch 457/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0890 - accuracy: 0.9626 - val_loss: 0.0395 - val_accuracy: 0.9850\n",
      "Epoch 458/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0938 - accuracy: 0.9621 - val_loss: 0.0394 - val_accuracy: 0.9845\n",
      "Epoch 459/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0926 - accuracy: 0.9619 - val_loss: 0.0435 - val_accuracy: 0.9855\n",
      "Epoch 460/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0925 - accuracy: 0.9630 - val_loss: 0.0387 - val_accuracy: 0.9853\n",
      "Epoch 461/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0914 - accuracy: 0.9630 - val_loss: 0.0573 - val_accuracy: 0.9834\n",
      "Epoch 462/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9617 - val_loss: 0.0473 - val_accuracy: 0.9840\n",
      "Epoch 463/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0916 - accuracy: 0.9635 - val_loss: 0.0430 - val_accuracy: 0.9795\n",
      "Epoch 464/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0911 - accuracy: 0.9615 - val_loss: 0.0341 - val_accuracy: 0.9872\n",
      "Epoch 465/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0899 - accuracy: 0.9640 - val_loss: 0.0584 - val_accuracy: 0.9853\n",
      "Epoch 466/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0901 - accuracy: 0.9632 - val_loss: 0.0395 - val_accuracy: 0.9845\n",
      "Epoch 467/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0888 - accuracy: 0.9636 - val_loss: 0.1130 - val_accuracy: 0.9708\n",
      "Epoch 468/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0937 - accuracy: 0.9629 - val_loss: 0.0486 - val_accuracy: 0.9843\n",
      "Epoch 469/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0922 - accuracy: 0.9625 - val_loss: 0.0418 - val_accuracy: 0.9869\n",
      "Epoch 470/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0927 - accuracy: 0.9636 - val_loss: 0.0694 - val_accuracy: 0.9823\n",
      "Epoch 471/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0929 - accuracy: 0.9631 - val_loss: 0.0457 - val_accuracy: 0.9808\n",
      "Epoch 472/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0918 - accuracy: 0.9631 - val_loss: 0.0533 - val_accuracy: 0.9805\n",
      "Epoch 473/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0908 - accuracy: 0.9638 - val_loss: 0.0472 - val_accuracy: 0.9808\n",
      "Epoch 474/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0930 - accuracy: 0.9623 - val_loss: 0.0431 - val_accuracy: 0.9850\n",
      "Epoch 475/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0913 - accuracy: 0.9627 - val_loss: 0.0446 - val_accuracy: 0.9835\n",
      "Epoch 476/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0941 - accuracy: 0.9634 - val_loss: 0.0426 - val_accuracy: 0.9829\n",
      "Epoch 477/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0930 - accuracy: 0.9628 - val_loss: 0.0456 - val_accuracy: 0.9826\n",
      "Epoch 478/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0971 - accuracy: 0.9620 - val_loss: 0.0672 - val_accuracy: 0.9707\n",
      "Epoch 479/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0889 - accuracy: 0.9631 - val_loss: 0.0514 - val_accuracy: 0.9817\n",
      "Epoch 480/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0898 - accuracy: 0.9636 - val_loss: 0.0574 - val_accuracy: 0.9828\n",
      "Epoch 481/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.0919 - accuracy: 0.9638 - val_loss: 0.0558 - val_accuracy: 0.9834\n",
      "Epoch 482/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0923 - accuracy: 0.9617 - val_loss: 0.0449 - val_accuracy: 0.9858\n",
      "Epoch 483/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0910 - accuracy: 0.9643 - val_loss: 0.0591 - val_accuracy: 0.9801\n",
      "Epoch 484/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0896 - accuracy: 0.9632 - val_loss: 0.0493 - val_accuracy: 0.9854\n",
      "Epoch 485/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0918 - accuracy: 0.9628 - val_loss: 0.0458 - val_accuracy: 0.9842\n",
      "Epoch 486/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0909 - accuracy: 0.9623 - val_loss: 0.0439 - val_accuracy: 0.9845\n",
      "Epoch 487/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0900 - accuracy: 0.9634 - val_loss: 0.0781 - val_accuracy: 0.9697\n",
      "Epoch 488/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0908 - accuracy: 0.9618 - val_loss: 0.0384 - val_accuracy: 0.9855\n",
      "Epoch 489/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0911 - accuracy: 0.9620 - val_loss: 0.0495 - val_accuracy: 0.9834\n",
      "Epoch 490/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0920 - accuracy: 0.9620 - val_loss: 0.1016 - val_accuracy: 0.9617\n",
      "Epoch 491/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0926 - accuracy: 0.9618 - val_loss: 0.0428 - val_accuracy: 0.9848\n",
      "Epoch 492/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0928 - accuracy: 0.9627 - val_loss: 0.0471 - val_accuracy: 0.9846\n",
      "Epoch 493/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0892 - accuracy: 0.9631 - val_loss: 0.0381 - val_accuracy: 0.9850\n",
      "Epoch 494/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0911 - accuracy: 0.9630 - val_loss: 0.0463 - val_accuracy: 0.9824\n",
      "Epoch 495/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9622 - val_loss: 0.0602 - val_accuracy: 0.9832\n",
      "Epoch 496/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0941 - accuracy: 0.9622 - val_loss: 0.0505 - val_accuracy: 0.9809\n",
      "Epoch 497/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0894 - accuracy: 0.9625 - val_loss: 0.0561 - val_accuracy: 0.9839\n",
      "Epoch 498/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0909 - accuracy: 0.9630 - val_loss: 0.0534 - val_accuracy: 0.9837\n",
      "Epoch 499/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0910 - accuracy: 0.9627 - val_loss: 0.0355 - val_accuracy: 0.9862\n",
      "Epoch 500/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0914 - accuracy: 0.9610 - val_loss: 0.0569 - val_accuracy: 0.9799\n",
      "Epoch 501/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0904 - accuracy: 0.9615 - val_loss: 0.0409 - val_accuracy: 0.9828\n",
      "Epoch 502/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0907 - accuracy: 0.9626 - val_loss: 0.0451 - val_accuracy: 0.9837\n",
      "Epoch 503/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0907 - accuracy: 0.9626 - val_loss: 0.0495 - val_accuracy: 0.9843\n",
      "Epoch 504/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0947 - accuracy: 0.9634 - val_loss: 0.0403 - val_accuracy: 0.9831\n",
      "Epoch 505/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0916 - accuracy: 0.9618 - val_loss: 0.0415 - val_accuracy: 0.9830\n",
      "Epoch 506/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0901 - accuracy: 0.9629 - val_loss: 0.0416 - val_accuracy: 0.9843\n",
      "Epoch 507/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0897 - accuracy: 0.9626 - val_loss: 0.0466 - val_accuracy: 0.9812\n",
      "Epoch 508/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0906 - accuracy: 0.9631 - val_loss: 0.0403 - val_accuracy: 0.9852\n",
      "Epoch 509/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9616 - val_loss: 0.0643 - val_accuracy: 0.9830\n",
      "Epoch 510/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0895 - accuracy: 0.9632 - val_loss: 0.0546 - val_accuracy: 0.9827\n",
      "Epoch 511/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0919 - accuracy: 0.9632 - val_loss: 0.0547 - val_accuracy: 0.9791\n",
      "Epoch 512/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0928 - accuracy: 0.9623 - val_loss: 0.0390 - val_accuracy: 0.9859\n",
      "Epoch 513/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0919 - accuracy: 0.9623 - val_loss: 0.0518 - val_accuracy: 0.9830\n",
      "Epoch 514/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0919 - accuracy: 0.9632 - val_loss: 0.0444 - val_accuracy: 0.9827\n",
      "Epoch 515/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0895 - accuracy: 0.9623 - val_loss: 0.0415 - val_accuracy: 0.9860\n",
      "Epoch 516/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0915 - accuracy: 0.9632 - val_loss: 0.0465 - val_accuracy: 0.9836\n",
      "Epoch 517/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0910 - accuracy: 0.9631 - val_loss: 0.0444 - val_accuracy: 0.9840\n",
      "Epoch 518/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.0912 - accuracy: 0.9626 - val_loss: 0.0399 - val_accuracy: 0.9821\n",
      "Epoch 519/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.1221 - accuracy: 0.9596 - val_loss: 0.0407 - val_accuracy: 0.9829\n",
      "Epoch 520/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0891 - accuracy: 0.9643 - val_loss: 0.0426 - val_accuracy: 0.9857\n",
      "Epoch 521/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0922 - accuracy: 0.9630 - val_loss: 0.0369 - val_accuracy: 0.9854\n",
      "Epoch 522/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.0920 - accuracy: 0.9630 - val_loss: 0.0905 - val_accuracy: 0.9818\n",
      "Epoch 523/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0895 - accuracy: 0.9640 - val_loss: 0.0412 - val_accuracy: 0.9837\n",
      "Epoch 524/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0957 - accuracy: 0.9614 - val_loss: 0.0375 - val_accuracy: 0.9875\n",
      "Epoch 525/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.1265 - accuracy: 0.9593 - val_loss: 0.0530 - val_accuracy: 0.9800\n",
      "Epoch 526/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.1075 - accuracy: 0.9621 - val_loss: 0.0358 - val_accuracy: 0.9854\n",
      "Epoch 527/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0873 - accuracy: 0.9633 - val_loss: 0.0468 - val_accuracy: 0.9848\n",
      "Epoch 528/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0919 - accuracy: 0.9620 - val_loss: 0.0427 - val_accuracy: 0.9848\n",
      "Epoch 529/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0893 - accuracy: 0.9631 - val_loss: 0.0592 - val_accuracy: 0.9803\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0921 - accuracy: 0.9625 - val_loss: 0.0587 - val_accuracy: 0.9733\n",
      "Epoch 531/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0933 - accuracy: 0.9623 - val_loss: 0.0405 - val_accuracy: 0.9811\n",
      "Epoch 532/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.1156 - accuracy: 0.9609 - val_loss: 0.0443 - val_accuracy: 0.9859\n",
      "Epoch 533/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0915 - accuracy: 0.9631 - val_loss: 0.0414 - val_accuracy: 0.9836\n",
      "Epoch 534/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0981 - accuracy: 0.9630 - val_loss: 0.0497 - val_accuracy: 0.9802\n",
      "Epoch 535/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0882 - accuracy: 0.9634 - val_loss: 0.0505 - val_accuracy: 0.9830\n",
      "Epoch 536/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0912 - accuracy: 0.9634 - val_loss: 0.0382 - val_accuracy: 0.9856\n",
      "Epoch 537/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0920 - accuracy: 0.9617 - val_loss: 0.0501 - val_accuracy: 0.9823\n",
      "Epoch 538/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0899 - accuracy: 0.9637 - val_loss: 0.0403 - val_accuracy: 0.9847\n",
      "Epoch 539/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0919 - accuracy: 0.9646 - val_loss: 0.0448 - val_accuracy: 0.9843\n",
      "Epoch 540/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0895 - accuracy: 0.9632 - val_loss: 0.0593 - val_accuracy: 0.9812\n",
      "Epoch 541/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0920 - accuracy: 0.9607 - val_loss: 0.0710 - val_accuracy: 0.9801\n",
      "Epoch 542/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0912 - accuracy: 0.9630 - val_loss: 0.0424 - val_accuracy: 0.9832\n",
      "Epoch 543/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0917 - accuracy: 0.9627 - val_loss: 0.0544 - val_accuracy: 0.9840\n",
      "Epoch 544/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0897 - accuracy: 0.9629 - val_loss: 0.0499 - val_accuracy: 0.9822\n",
      "Epoch 545/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0906 - accuracy: 0.9629 - val_loss: 0.0556 - val_accuracy: 0.9792\n",
      "Epoch 546/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0914 - accuracy: 0.9617 - val_loss: 0.0413 - val_accuracy: 0.9847\n",
      "Epoch 547/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0924 - accuracy: 0.9610 - val_loss: 0.0479 - val_accuracy: 0.9811\n",
      "Epoch 548/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0928 - accuracy: 0.9627 - val_loss: 0.0372 - val_accuracy: 0.9866\n",
      "Epoch 549/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0941 - accuracy: 0.9628 - val_loss: 0.0555 - val_accuracy: 0.9845\n",
      "Epoch 550/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0884 - accuracy: 0.9624 - val_loss: 0.0414 - val_accuracy: 0.9844\n",
      "Epoch 551/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.0905 - accuracy: 0.9619 - val_loss: 0.0404 - val_accuracy: 0.9809\n",
      "Epoch 552/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0899 - accuracy: 0.9635 - val_loss: 0.0424 - val_accuracy: 0.9829\n",
      "Epoch 553/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0896 - accuracy: 0.9621 - val_loss: 0.0497 - val_accuracy: 0.9819\n",
      "Epoch 554/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9619 - val_loss: 0.0435 - val_accuracy: 0.9840\n",
      "Epoch 555/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.0900 - accuracy: 0.9624 - val_loss: 0.0619 - val_accuracy: 0.9823\n",
      "Epoch 556/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0907 - accuracy: 0.9626 - val_loss: 0.0555 - val_accuracy: 0.9782\n",
      "Epoch 557/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.9619 - val_loss: 0.0389 - val_accuracy: 0.9856\n",
      "Epoch 558/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0890 - accuracy: 0.9636 - val_loss: 0.0456 - val_accuracy: 0.9835\n",
      "Epoch 559/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0930 - accuracy: 0.9630 - val_loss: 0.0803 - val_accuracy: 0.9804\n",
      "Epoch 560/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0883 - accuracy: 0.9634 - val_loss: 0.0366 - val_accuracy: 0.9853\n",
      "Epoch 561/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0904 - accuracy: 0.9625 - val_loss: 0.0547 - val_accuracy: 0.9761\n",
      "Epoch 562/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0892 - accuracy: 0.9634 - val_loss: 0.0387 - val_accuracy: 0.9850\n",
      "Epoch 563/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0898 - accuracy: 0.9626 - val_loss: 0.0503 - val_accuracy: 0.9830\n",
      "Epoch 564/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0890 - accuracy: 0.9640 - val_loss: 0.0567 - val_accuracy: 0.9808\n",
      "Epoch 565/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0902 - accuracy: 0.9612 - val_loss: 0.0451 - val_accuracy: 0.9829\n",
      "Epoch 566/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0909 - accuracy: 0.9640 - val_loss: 0.0608 - val_accuracy: 0.9798\n",
      "Epoch 567/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0918 - accuracy: 0.9630 - val_loss: 0.0495 - val_accuracy: 0.9843\n",
      "Epoch 568/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0898 - accuracy: 0.9635 - val_loss: 0.0541 - val_accuracy: 0.9788\n",
      "Epoch 569/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0887 - accuracy: 0.9625 - val_loss: 0.0409 - val_accuracy: 0.9853\n",
      "Epoch 570/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0905 - accuracy: 0.9620 - val_loss: 0.0506 - val_accuracy: 0.9820\n",
      "Epoch 571/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0915 - accuracy: 0.9628 - val_loss: 0.0582 - val_accuracy: 0.9857\n",
      "Epoch 572/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0913 - accuracy: 0.9628 - val_loss: 0.0434 - val_accuracy: 0.9847\n",
      "Epoch 573/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0906 - accuracy: 0.9617 - val_loss: 0.0382 - val_accuracy: 0.9859\n",
      "Epoch 574/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0927 - accuracy: 0.9642 - val_loss: 0.0366 - val_accuracy: 0.9845\n",
      "Epoch 575/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0872 - accuracy: 0.9634 - val_loss: 0.0439 - val_accuracy: 0.9827\n",
      "Epoch 576/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0894 - accuracy: 0.9635 - val_loss: 0.0470 - val_accuracy: 0.9806\n",
      "Epoch 577/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0899 - accuracy: 0.9622 - val_loss: 0.0437 - val_accuracy: 0.9850\n",
      "Epoch 578/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0890 - accuracy: 0.9635 - val_loss: 0.0435 - val_accuracy: 0.9865\n",
      "Epoch 579/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0898 - accuracy: 0.9640 - val_loss: 0.0384 - val_accuracy: 0.9852\n",
      "Epoch 580/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0898 - accuracy: 0.9630 - val_loss: 0.0617 - val_accuracy: 0.9794\n",
      "Epoch 581/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0893 - accuracy: 0.9628 - val_loss: 0.0561 - val_accuracy: 0.9805\n",
      "Epoch 582/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0896 - accuracy: 0.9620 - val_loss: 0.0519 - val_accuracy: 0.9788\n",
      "Epoch 583/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0907 - accuracy: 0.9632 - val_loss: 0.0397 - val_accuracy: 0.9846\n",
      "Epoch 584/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0928 - accuracy: 0.9632 - val_loss: 0.0438 - val_accuracy: 0.9821\n",
      "Epoch 585/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0911 - accuracy: 0.9639 - val_loss: 0.0420 - val_accuracy: 0.9837\n",
      "Epoch 586/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0896 - accuracy: 0.9631 - val_loss: 0.0381 - val_accuracy: 0.9867\n",
      "Epoch 587/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0911 - accuracy: 0.9631 - val_loss: 0.0448 - val_accuracy: 0.9847\n",
      "Epoch 588/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0900 - accuracy: 0.9634 - val_loss: 0.0445 - val_accuracy: 0.9831\n",
      "Epoch 589/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0916 - accuracy: 0.9632 - val_loss: 0.0526 - val_accuracy: 0.9855\n",
      "Epoch 590/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0901 - accuracy: 0.9629 - val_loss: 0.0384 - val_accuracy: 0.9836\n",
      "Epoch 591/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0895 - accuracy: 0.9627 - val_loss: 0.0470 - val_accuracy: 0.9854\n",
      "Epoch 592/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0885 - accuracy: 0.9640 - val_loss: 0.0377 - val_accuracy: 0.9839\n",
      "Epoch 593/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0894 - accuracy: 0.9634 - val_loss: 0.0388 - val_accuracy: 0.9842\n",
      "Epoch 594/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.9637 - val_loss: 0.0390 - val_accuracy: 0.9840\n",
      "Epoch 595/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0894 - accuracy: 0.9643 - val_loss: 0.0351 - val_accuracy: 0.9865\n",
      "Epoch 596/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0894 - accuracy: 0.9634 - val_loss: 0.0413 - val_accuracy: 0.9853\n",
      "Epoch 597/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0882 - accuracy: 0.9635 - val_loss: 0.0466 - val_accuracy: 0.9823\n",
      "Epoch 598/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0911 - accuracy: 0.9635 - val_loss: 0.0494 - val_accuracy: 0.9824\n",
      "Epoch 599/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0891 - accuracy: 0.9632 - val_loss: 0.0424 - val_accuracy: 0.9827\n",
      "Epoch 600/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0896 - accuracy: 0.9634 - val_loss: 0.0541 - val_accuracy: 0.9827\n",
      "Epoch 601/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0920 - accuracy: 0.9615 - val_loss: 0.0402 - val_accuracy: 0.9856\n",
      "Epoch 602/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0889 - accuracy: 0.9629 - val_loss: 0.0396 - val_accuracy: 0.9847\n",
      "Epoch 603/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0886 - accuracy: 0.9633 - val_loss: 0.0477 - val_accuracy: 0.9798\n",
      "Epoch 604/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0914 - accuracy: 0.9626 - val_loss: 0.0448 - val_accuracy: 0.9847\n",
      "Epoch 605/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0890 - accuracy: 0.9620 - val_loss: 0.0528 - val_accuracy: 0.9844\n",
      "Epoch 606/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0907 - accuracy: 0.9634 - val_loss: 0.0411 - val_accuracy: 0.9848\n",
      "Epoch 607/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0895 - accuracy: 0.9629 - val_loss: 0.0681 - val_accuracy: 0.9797\n",
      "Epoch 608/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9635 - val_loss: 0.0465 - val_accuracy: 0.9843\n",
      "Epoch 609/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0902 - accuracy: 0.9627 - val_loss: 0.0543 - val_accuracy: 0.9843\n",
      "Epoch 610/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0903 - accuracy: 0.9631 - val_loss: 0.0451 - val_accuracy: 0.9850\n",
      "Epoch 611/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.9633 - val_loss: 0.0453 - val_accuracy: 0.9853\n",
      "Epoch 612/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0950 - accuracy: 0.9637 - val_loss: 0.0418 - val_accuracy: 0.9857\n",
      "Epoch 613/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0920 - accuracy: 0.9627 - val_loss: 0.0811 - val_accuracy: 0.9736\n",
      "Epoch 614/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0885 - accuracy: 0.9637 - val_loss: 0.0424 - val_accuracy: 0.9851\n",
      "Epoch 615/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0889 - accuracy: 0.9626 - val_loss: 0.0550 - val_accuracy: 0.9835\n",
      "Epoch 616/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0901 - accuracy: 0.9629 - val_loss: 0.0375 - val_accuracy: 0.9854\n",
      "Epoch 617/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.1351 - accuracy: 0.9596 - val_loss: 0.0373 - val_accuracy: 0.9852\n",
      "Epoch 618/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0885 - accuracy: 0.9621 - val_loss: 0.0406 - val_accuracy: 0.9843\n",
      "Epoch 619/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0915 - accuracy: 0.9613 - val_loss: 0.0374 - val_accuracy: 0.9852\n",
      "Epoch 620/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0878 - accuracy: 0.9646 - val_loss: 0.0427 - val_accuracy: 0.9839\n",
      "Epoch 621/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0923 - accuracy: 0.9636 - val_loss: 0.0458 - val_accuracy: 0.9847\n",
      "Epoch 622/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0923 - accuracy: 0.9631 - val_loss: 0.0369 - val_accuracy: 0.9859\n",
      "Epoch 623/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0865 - accuracy: 0.9638 - val_loss: 0.0431 - val_accuracy: 0.9808\n",
      "Epoch 624/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0896 - accuracy: 0.9644 - val_loss: 0.0533 - val_accuracy: 0.9810\n",
      "Epoch 625/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0876 - accuracy: 0.9622 - val_loss: 0.0372 - val_accuracy: 0.9869\n",
      "Epoch 626/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0864 - accuracy: 0.9636 - val_loss: 0.0456 - val_accuracy: 0.9824\n",
      "Epoch 627/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0886 - accuracy: 0.9625 - val_loss: 0.0556 - val_accuracy: 0.9843\n",
      "Epoch 628/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0904 - accuracy: 0.9640 - val_loss: 0.0433 - val_accuracy: 0.9863\n",
      "Epoch 629/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0927 - accuracy: 0.9629 - val_loss: 0.0410 - val_accuracy: 0.9852\n",
      "Epoch 630/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0904 - accuracy: 0.9635 - val_loss: 0.0407 - val_accuracy: 0.9847\n",
      "Epoch 631/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0891 - accuracy: 0.9636 - val_loss: 0.0399 - val_accuracy: 0.9860\n",
      "Epoch 632/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0888 - accuracy: 0.9636 - val_loss: 0.0458 - val_accuracy: 0.9849\n",
      "Epoch 633/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0877 - accuracy: 0.9630 - val_loss: 0.0927 - val_accuracy: 0.9691\n",
      "Epoch 634/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0894 - accuracy: 0.9638 - val_loss: 0.0491 - val_accuracy: 0.9834\n",
      "Epoch 635/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0876 - accuracy: 0.9635 - val_loss: 0.0413 - val_accuracy: 0.9834\n",
      "Epoch 636/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0902 - accuracy: 0.9632 - val_loss: 0.0412 - val_accuracy: 0.9867\n",
      "Epoch 637/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0899 - accuracy: 0.9621 - val_loss: 0.0467 - val_accuracy: 0.9825\n",
      "Epoch 638/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0900 - accuracy: 0.9635 - val_loss: 0.0445 - val_accuracy: 0.9832\n",
      "Epoch 639/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0896 - accuracy: 0.9644 - val_loss: 0.0378 - val_accuracy: 0.9865\n",
      "Epoch 640/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0892 - accuracy: 0.9628 - val_loss: 0.0373 - val_accuracy: 0.9850\n",
      "Epoch 641/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0888 - accuracy: 0.9626 - val_loss: 0.0427 - val_accuracy: 0.9855\n",
      "Epoch 642/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0902 - accuracy: 0.9636 - val_loss: 0.0521 - val_accuracy: 0.9798\n",
      "Epoch 643/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1295 - accuracy: 0.9587 - val_loss: 0.0385 - val_accuracy: 0.9851\n",
      "Epoch 644/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1467 - accuracy: 0.9592 - val_loss: 0.0421 - val_accuracy: 0.9855\n",
      "Epoch 645/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0877 - accuracy: 0.9632 - val_loss: 0.0363 - val_accuracy: 0.9850\n",
      "Epoch 646/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0873 - accuracy: 0.9622 - val_loss: 0.0483 - val_accuracy: 0.9827\n",
      "Epoch 647/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0867 - accuracy: 0.9635 - val_loss: 0.0530 - val_accuracy: 0.9805\n",
      "Epoch 648/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0927 - accuracy: 0.9626 - val_loss: 0.0372 - val_accuracy: 0.9855\n",
      "Epoch 649/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0904 - accuracy: 0.9631 - val_loss: 0.0503 - val_accuracy: 0.9817\n",
      "Epoch 650/1000\n",
      "20631/20631 [==============================] - 0s 24us/sample - loss: 0.0876 - accuracy: 0.9644 - val_loss: 0.0400 - val_accuracy: 0.9843\n",
      "Epoch 651/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.0912 - accuracy: 0.9637 - val_loss: 0.0591 - val_accuracy: 0.9752\n",
      "Epoch 652/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0894 - accuracy: 0.9631 - val_loss: 0.0423 - val_accuracy: 0.9837\n",
      "Epoch 653/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0879 - accuracy: 0.9643 - val_loss: 0.0524 - val_accuracy: 0.9837\n",
      "Epoch 654/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0886 - accuracy: 0.9631 - val_loss: 0.0406 - val_accuracy: 0.9853\n",
      "Epoch 655/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.0898 - accuracy: 0.9628 - val_loss: 0.0416 - val_accuracy: 0.9838\n",
      "Epoch 656/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0902 - accuracy: 0.9624 - val_loss: 0.0391 - val_accuracy: 0.9850\n",
      "Epoch 657/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0879 - accuracy: 0.9644 - val_loss: 0.0683 - val_accuracy: 0.9679\n",
      "Epoch 658/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0921 - accuracy: 0.9611 - val_loss: 0.0894 - val_accuracy: 0.9620\n",
      "Epoch 659/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0905 - accuracy: 0.9622 - val_loss: 0.0434 - val_accuracy: 0.9832\n",
      "Epoch 660/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0884 - accuracy: 0.9631 - val_loss: 0.0408 - val_accuracy: 0.9836\n",
      "Epoch 661/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0904 - accuracy: 0.9633 - val_loss: 0.0485 - val_accuracy: 0.9796\n",
      "Epoch 662/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0907 - accuracy: 0.9620 - val_loss: 0.0433 - val_accuracy: 0.9816\n",
      "Epoch 663/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0881 - accuracy: 0.9635 - val_loss: 0.0417 - val_accuracy: 0.9845\n",
      "Epoch 664/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0881 - accuracy: 0.9632 - val_loss: 0.0413 - val_accuracy: 0.9815\n",
      "Epoch 665/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0889 - accuracy: 0.9649 - val_loss: 0.0477 - val_accuracy: 0.9811\n",
      "Epoch 666/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0895 - accuracy: 0.9634 - val_loss: 0.0593 - val_accuracy: 0.9782\n",
      "Epoch 667/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0916 - accuracy: 0.9630 - val_loss: 0.0433 - val_accuracy: 0.9837\n",
      "Epoch 668/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0894 - accuracy: 0.9640 - val_loss: 0.0441 - val_accuracy: 0.9836\n",
      "Epoch 669/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0893 - accuracy: 0.9636 - val_loss: 0.0428 - val_accuracy: 0.9849\n",
      "Epoch 670/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0895 - accuracy: 0.9643 - val_loss: 0.0443 - val_accuracy: 0.9840\n",
      "Epoch 671/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9626 - val_loss: 0.0381 - val_accuracy: 0.9841\n",
      "Epoch 672/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0870 - accuracy: 0.9641 - val_loss: 0.0483 - val_accuracy: 0.9882\n",
      "Epoch 673/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0889 - accuracy: 0.9637 - val_loss: 0.0390 - val_accuracy: 0.9847\n",
      "Epoch 674/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0909 - accuracy: 0.9631 - val_loss: 0.0413 - val_accuracy: 0.9847\n",
      "Epoch 675/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0927 - accuracy: 0.9619 - val_loss: 0.0435 - val_accuracy: 0.9817\n",
      "Epoch 676/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0881 - accuracy: 0.9634 - val_loss: 0.0443 - val_accuracy: 0.9863\n",
      "Epoch 677/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0886 - accuracy: 0.9644 - val_loss: 0.0413 - val_accuracy: 0.9863\n",
      "Epoch 678/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0892 - accuracy: 0.9629 - val_loss: 0.0450 - val_accuracy: 0.9827\n",
      "Epoch 679/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0901 - accuracy: 0.9643 - val_loss: 0.0472 - val_accuracy: 0.9808\n",
      "Epoch 680/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0885 - accuracy: 0.9621 - val_loss: 0.0458 - val_accuracy: 0.9832\n",
      "Epoch 681/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0887 - accuracy: 0.9631 - val_loss: 0.0566 - val_accuracy: 0.9845\n",
      "Epoch 682/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.9629 - val_loss: 0.0462 - val_accuracy: 0.9842\n",
      "Epoch 683/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0914 - accuracy: 0.9634 - val_loss: 0.0670 - val_accuracy: 0.9829\n",
      "Epoch 684/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.9631 - val_loss: 0.0437 - val_accuracy: 0.9846\n",
      "Epoch 685/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0890 - accuracy: 0.9632 - val_loss: 0.0429 - val_accuracy: 0.9837\n",
      "Epoch 686/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0899 - accuracy: 0.9621 - val_loss: 0.0629 - val_accuracy: 0.9832\n",
      "Epoch 687/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0915 - accuracy: 0.9628 - val_loss: 0.0410 - val_accuracy: 0.9859\n",
      "Epoch 688/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0879 - accuracy: 0.9627 - val_loss: 0.0662 - val_accuracy: 0.9830\n",
      "Epoch 689/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0876 - accuracy: 0.9644 - val_loss: 0.0469 - val_accuracy: 0.9863\n",
      "Epoch 690/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0889 - accuracy: 0.9641 - val_loss: 0.0584 - val_accuracy: 0.9815\n",
      "Epoch 691/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0900 - accuracy: 0.9632 - val_loss: 0.0376 - val_accuracy: 0.9853\n",
      "Epoch 692/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0904 - accuracy: 0.9641 - val_loss: 0.0565 - val_accuracy: 0.9837\n",
      "Epoch 693/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0894 - accuracy: 0.9636 - val_loss: 0.0519 - val_accuracy: 0.9797\n",
      "Epoch 694/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0887 - accuracy: 0.9633 - val_loss: 0.0406 - val_accuracy: 0.9854\n",
      "Epoch 695/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0896 - accuracy: 0.9623 - val_loss: 0.0485 - val_accuracy: 0.9823\n",
      "Epoch 696/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0888 - accuracy: 0.9640 - val_loss: 0.0537 - val_accuracy: 0.9779\n",
      "Epoch 697/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0907 - accuracy: 0.9634 - val_loss: 0.0789 - val_accuracy: 0.9731\n",
      "Epoch 698/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0882 - accuracy: 0.9627 - val_loss: 0.0522 - val_accuracy: 0.9812\n",
      "Epoch 699/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0903 - accuracy: 0.9637 - val_loss: 0.0595 - val_accuracy: 0.9803\n",
      "Epoch 700/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0871 - accuracy: 0.9635 - val_loss: 0.0481 - val_accuracy: 0.9850\n",
      "Epoch 701/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0875 - accuracy: 0.9626 - val_loss: 0.0736 - val_accuracy: 0.9792\n",
      "Epoch 702/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0930 - accuracy: 0.9619 - val_loss: 0.0447 - val_accuracy: 0.9850\n",
      "Epoch 703/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0889 - accuracy: 0.9631 - val_loss: 0.0656 - val_accuracy: 0.9776\n",
      "Epoch 704/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0875 - accuracy: 0.9638 - val_loss: 0.0453 - val_accuracy: 0.9825\n",
      "Epoch 705/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0913 - accuracy: 0.9638 - val_loss: 0.0575 - val_accuracy: 0.9822\n",
      "Epoch 706/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0910 - accuracy: 0.9624 - val_loss: 0.0638 - val_accuracy: 0.9763\n",
      "Epoch 707/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0896 - accuracy: 0.9621 - val_loss: 0.0627 - val_accuracy: 0.9787\n",
      "Epoch 708/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0893 - accuracy: 0.9634 - val_loss: 0.0443 - val_accuracy: 0.9827\n",
      "Epoch 709/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0882 - accuracy: 0.9628 - val_loss: 0.0418 - val_accuracy: 0.9853\n",
      "Epoch 710/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0889 - accuracy: 0.9635 - val_loss: 0.0407 - val_accuracy: 0.9865\n",
      "Epoch 711/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0904 - accuracy: 0.9622 - val_loss: 0.0798 - val_accuracy: 0.9734\n",
      "Epoch 712/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0877 - accuracy: 0.9639 - val_loss: 0.0486 - val_accuracy: 0.9845\n",
      "Epoch 713/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0864 - accuracy: 0.9640 - val_loss: 0.0565 - val_accuracy: 0.9844\n",
      "Epoch 714/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0893 - accuracy: 0.9642 - val_loss: 0.0455 - val_accuracy: 0.9859\n",
      "Epoch 715/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0856 - accuracy: 0.9632 - val_loss: 0.0423 - val_accuracy: 0.9863\n",
      "Epoch 716/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0877 - accuracy: 0.9654 - val_loss: 0.0386 - val_accuracy: 0.9847\n",
      "Epoch 717/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0896 - accuracy: 0.9641 - val_loss: 0.0417 - val_accuracy: 0.9843\n",
      "Epoch 718/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0905 - accuracy: 0.9623 - val_loss: 0.0416 - val_accuracy: 0.9824\n",
      "Epoch 719/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0916 - accuracy: 0.9628 - val_loss: 0.0381 - val_accuracy: 0.9841\n",
      "Epoch 720/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0893 - accuracy: 0.9628 - val_loss: 0.0671 - val_accuracy: 0.9745\n",
      "Epoch 721/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0903 - accuracy: 0.9620 - val_loss: 0.0705 - val_accuracy: 0.9814\n",
      "Epoch 722/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0962 - accuracy: 0.9632 - val_loss: 0.0471 - val_accuracy: 0.9835\n",
      "Epoch 723/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0889 - accuracy: 0.9630 - val_loss: 0.0400 - val_accuracy: 0.9859\n",
      "Epoch 724/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0898 - accuracy: 0.9627 - val_loss: 0.0444 - val_accuracy: 0.9857\n",
      "Epoch 725/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0928 - accuracy: 0.9622 - val_loss: 0.0448 - val_accuracy: 0.9837\n",
      "Epoch 726/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0907 - accuracy: 0.9636 - val_loss: 0.0385 - val_accuracy: 0.9849\n",
      "Epoch 727/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0879 - accuracy: 0.9637 - val_loss: 0.0436 - val_accuracy: 0.9840\n",
      "Epoch 728/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0874 - accuracy: 0.9635 - val_loss: 0.0734 - val_accuracy: 0.9803\n",
      "Epoch 729/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0892 - accuracy: 0.9636 - val_loss: 0.0583 - val_accuracy: 0.9846\n",
      "Epoch 730/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0880 - accuracy: 0.9636 - val_loss: 0.0465 - val_accuracy: 0.9833\n",
      "Epoch 731/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0875 - accuracy: 0.9630 - val_loss: 0.0451 - val_accuracy: 0.9836\n",
      "Epoch 732/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0904 - accuracy: 0.9639 - val_loss: 0.0500 - val_accuracy: 0.9788\n",
      "Epoch 733/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0895 - accuracy: 0.9625 - val_loss: 0.0371 - val_accuracy: 0.9859\n",
      "Epoch 734/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0902 - accuracy: 0.9646 - val_loss: 0.0496 - val_accuracy: 0.9840\n",
      "Epoch 735/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0915 - accuracy: 0.9637 - val_loss: 0.0421 - val_accuracy: 0.9832\n",
      "Epoch 736/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0896 - accuracy: 0.9633 - val_loss: 0.1172 - val_accuracy: 0.9692\n",
      "Epoch 737/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0929 - accuracy: 0.9638 - val_loss: 0.0409 - val_accuracy: 0.9843\n",
      "Epoch 738/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0891 - accuracy: 0.9645 - val_loss: 0.0947 - val_accuracy: 0.9663\n",
      "Epoch 739/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0905 - accuracy: 0.9628 - val_loss: 0.0529 - val_accuracy: 0.9801\n",
      "Epoch 740/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0905 - accuracy: 0.9643 - val_loss: 0.0594 - val_accuracy: 0.9774\n",
      "Epoch 741/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0875 - accuracy: 0.9641 - val_loss: 0.0391 - val_accuracy: 0.9857\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0883 - accuracy: 0.9640 - val_loss: 0.0435 - val_accuracy: 0.9819\n",
      "Epoch 743/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0877 - accuracy: 0.9626 - val_loss: 0.0374 - val_accuracy: 0.9859\n",
      "Epoch 744/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.0883 - accuracy: 0.9626 - val_loss: 0.0557 - val_accuracy: 0.9810\n",
      "Epoch 745/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0904 - accuracy: 0.9640 - val_loss: 0.0911 - val_accuracy: 0.9563\n",
      "Epoch 746/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0934 - accuracy: 0.9633 - val_loss: 0.0471 - val_accuracy: 0.9860\n",
      "Epoch 747/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0876 - accuracy: 0.9647 - val_loss: 0.0681 - val_accuracy: 0.9761\n",
      "Epoch 748/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0883 - accuracy: 0.9623 - val_loss: 0.0573 - val_accuracy: 0.9811\n",
      "Epoch 749/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0904 - accuracy: 0.9643 - val_loss: 0.0616 - val_accuracy: 0.9794\n",
      "Epoch 750/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0898 - accuracy: 0.9632 - val_loss: 0.0542 - val_accuracy: 0.9822\n",
      "Epoch 751/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0880 - accuracy: 0.9634 - val_loss: 0.0421 - val_accuracy: 0.9845\n",
      "Epoch 752/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.0914 - accuracy: 0.9636 - val_loss: 0.0426 - val_accuracy: 0.9839\n",
      "Epoch 753/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0895 - accuracy: 0.9634 - val_loss: 0.0438 - val_accuracy: 0.9859\n",
      "Epoch 754/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0875 - accuracy: 0.9628 - val_loss: 0.0445 - val_accuracy: 0.9836\n",
      "Epoch 755/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0892 - accuracy: 0.9614 - val_loss: 0.0393 - val_accuracy: 0.9851\n",
      "Epoch 756/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0866 - accuracy: 0.9637 - val_loss: 0.0497 - val_accuracy: 0.9857\n",
      "Epoch 757/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0890 - accuracy: 0.9628 - val_loss: 0.0431 - val_accuracy: 0.9826\n",
      "Epoch 758/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0879 - accuracy: 0.9628 - val_loss: 0.0422 - val_accuracy: 0.9829\n",
      "Epoch 759/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0894 - accuracy: 0.9638 - val_loss: 0.0586 - val_accuracy: 0.9791\n",
      "Epoch 760/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0891 - accuracy: 0.9634 - val_loss: 0.0457 - val_accuracy: 0.9841\n",
      "Epoch 761/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1123 - accuracy: 0.9613 - val_loss: 0.0636 - val_accuracy: 0.9809\n",
      "Epoch 762/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0865 - accuracy: 0.9631 - val_loss: 0.0400 - val_accuracy: 0.9872\n",
      "Epoch 763/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0886 - accuracy: 0.9645 - val_loss: 0.0403 - val_accuracy: 0.9863\n",
      "Epoch 764/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0882 - accuracy: 0.9632 - val_loss: 0.0410 - val_accuracy: 0.9847\n",
      "Epoch 765/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0874 - accuracy: 0.9638 - val_loss: 0.0481 - val_accuracy: 0.9826\n",
      "Epoch 766/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0884 - accuracy: 0.9633 - val_loss: 0.0414 - val_accuracy: 0.9840\n",
      "Epoch 767/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0867 - accuracy: 0.9640 - val_loss: 0.0418 - val_accuracy: 0.9843\n",
      "Epoch 768/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0859 - accuracy: 0.9644 - val_loss: 0.0431 - val_accuracy: 0.9847\n",
      "Epoch 769/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0872 - accuracy: 0.9635 - val_loss: 0.0667 - val_accuracy: 0.9840\n",
      "Epoch 770/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0885 - accuracy: 0.9638 - val_loss: 0.0426 - val_accuracy: 0.9828\n",
      "Epoch 771/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0883 - accuracy: 0.9633 - val_loss: 0.0453 - val_accuracy: 0.9819\n",
      "Epoch 772/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0889 - accuracy: 0.9647 - val_loss: 0.0352 - val_accuracy: 0.9866\n",
      "Epoch 773/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0896 - accuracy: 0.9633 - val_loss: 0.0375 - val_accuracy: 0.9850\n",
      "Epoch 774/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0873 - accuracy: 0.9636 - val_loss: 0.0469 - val_accuracy: 0.9801\n",
      "Epoch 775/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0891 - accuracy: 0.9641 - val_loss: 0.0390 - val_accuracy: 0.9847\n",
      "Epoch 776/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0902 - accuracy: 0.9639 - val_loss: 0.0419 - val_accuracy: 0.9837\n",
      "Epoch 777/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0848 - accuracy: 0.9639 - val_loss: 0.0458 - val_accuracy: 0.9818\n",
      "Epoch 778/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0893 - accuracy: 0.9642 - val_loss: 0.0429 - val_accuracy: 0.9841\n",
      "Epoch 779/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0880 - accuracy: 0.9635 - val_loss: 0.0423 - val_accuracy: 0.9830\n",
      "Epoch 780/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0896 - accuracy: 0.9620 - val_loss: 0.0532 - val_accuracy: 0.9824\n",
      "Epoch 781/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0919 - accuracy: 0.9633 - val_loss: 0.0423 - val_accuracy: 0.9837\n",
      "Epoch 782/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0918 - accuracy: 0.9633 - val_loss: 0.0539 - val_accuracy: 0.9821\n",
      "Epoch 783/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0879 - accuracy: 0.9628 - val_loss: 0.0373 - val_accuracy: 0.9870\n",
      "Epoch 784/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0920 - accuracy: 0.9622 - val_loss: 0.0504 - val_accuracy: 0.9819\n",
      "Epoch 785/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0879 - accuracy: 0.9628 - val_loss: 0.0441 - val_accuracy: 0.9835\n",
      "Epoch 786/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0880 - accuracy: 0.9643 - val_loss: 0.0409 - val_accuracy: 0.9847\n",
      "Epoch 787/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0880 - accuracy: 0.9654 - val_loss: 0.0437 - val_accuracy: 0.9851\n",
      "Epoch 788/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0881 - accuracy: 0.9644 - val_loss: 0.0581 - val_accuracy: 0.9836\n",
      "Epoch 789/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0893 - accuracy: 0.9631 - val_loss: 0.0422 - val_accuracy: 0.9839\n",
      "Epoch 790/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0882 - accuracy: 0.9637 - val_loss: 0.0563 - val_accuracy: 0.9850\n",
      "Epoch 791/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0915 - accuracy: 0.9623 - val_loss: 0.0467 - val_accuracy: 0.9811\n",
      "Epoch 792/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0929 - accuracy: 0.9646 - val_loss: 0.0614 - val_accuracy: 0.9771\n",
      "Epoch 793/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0863 - accuracy: 0.9633 - val_loss: 0.0417 - val_accuracy: 0.9834\n",
      "Epoch 794/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0880 - accuracy: 0.9640 - val_loss: 0.0441 - val_accuracy: 0.9836\n",
      "Epoch 795/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0870 - accuracy: 0.9637 - val_loss: 0.0451 - val_accuracy: 0.9830\n",
      "Epoch 796/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0888 - accuracy: 0.9638 - val_loss: 0.0405 - val_accuracy: 0.9855\n",
      "Epoch 797/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0870 - accuracy: 0.9642 - val_loss: 0.0545 - val_accuracy: 0.9795\n",
      "Epoch 798/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0894 - accuracy: 0.9622 - val_loss: 0.0511 - val_accuracy: 0.9827\n",
      "Epoch 799/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0902 - accuracy: 0.9632 - val_loss: 0.0635 - val_accuracy: 0.9795\n",
      "Epoch 800/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0872 - accuracy: 0.9630 - val_loss: 0.0448 - val_accuracy: 0.9852\n",
      "Epoch 801/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0918 - accuracy: 0.9620 - val_loss: 0.0578 - val_accuracy: 0.9801\n",
      "Epoch 802/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0916 - accuracy: 0.9622 - val_loss: 0.0677 - val_accuracy: 0.9803\n",
      "Epoch 803/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0892 - accuracy: 0.9635 - val_loss: 0.0437 - val_accuracy: 0.9839\n",
      "Epoch 804/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0928 - accuracy: 0.9623 - val_loss: 0.0435 - val_accuracy: 0.9831\n",
      "Epoch 805/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0879 - accuracy: 0.9635 - val_loss: 0.0416 - val_accuracy: 0.9842\n",
      "Epoch 806/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0871 - accuracy: 0.9647 - val_loss: 0.0482 - val_accuracy: 0.9864\n",
      "Epoch 807/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0885 - accuracy: 0.9642 - val_loss: 0.0520 - val_accuracy: 0.9805\n",
      "Epoch 808/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0864 - accuracy: 0.9640 - val_loss: 0.0464 - val_accuracy: 0.9804\n",
      "Epoch 809/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0885 - accuracy: 0.9637 - val_loss: 0.0411 - val_accuracy: 0.9856\n",
      "Epoch 810/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0875 - accuracy: 0.9646 - val_loss: 0.0545 - val_accuracy: 0.9811\n",
      "Epoch 811/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0880 - accuracy: 0.9631 - val_loss: 0.0617 - val_accuracy: 0.9838\n",
      "Epoch 812/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0864 - accuracy: 0.9631 - val_loss: 0.0419 - val_accuracy: 0.9823\n",
      "Epoch 813/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0896 - accuracy: 0.9645 - val_loss: 0.0399 - val_accuracy: 0.9839\n",
      "Epoch 814/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0889 - accuracy: 0.9636 - val_loss: 0.0382 - val_accuracy: 0.9858\n",
      "Epoch 815/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0890 - accuracy: 0.9643 - val_loss: 0.0439 - val_accuracy: 0.9821\n",
      "Epoch 816/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0859 - accuracy: 0.9643 - val_loss: 0.0448 - val_accuracy: 0.9851\n",
      "Epoch 817/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0880 - accuracy: 0.9636 - val_loss: 0.0392 - val_accuracy: 0.9856\n",
      "Epoch 818/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0893 - accuracy: 0.9639 - val_loss: 0.0381 - val_accuracy: 0.9853\n",
      "Epoch 819/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0889 - accuracy: 0.9635 - val_loss: 0.0827 - val_accuracy: 0.9770\n",
      "Epoch 820/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0896 - accuracy: 0.9637 - val_loss: 0.0872 - val_accuracy: 0.9774\n",
      "Epoch 821/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0870 - accuracy: 0.9640 - val_loss: 0.0392 - val_accuracy: 0.9863\n",
      "Epoch 822/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0888 - accuracy: 0.9637 - val_loss: 0.0378 - val_accuracy: 0.9858\n",
      "Epoch 823/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0882 - accuracy: 0.9640 - val_loss: 0.0419 - val_accuracy: 0.9845\n",
      "Epoch 824/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0877 - accuracy: 0.9636 - val_loss: 0.0456 - val_accuracy: 0.9840\n",
      "Epoch 825/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0876 - accuracy: 0.9636 - val_loss: 0.0395 - val_accuracy: 0.9850\n",
      "Epoch 826/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0874 - accuracy: 0.9647 - val_loss: 0.0556 - val_accuracy: 0.9807\n",
      "Epoch 827/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0886 - accuracy: 0.9634 - val_loss: 0.0445 - val_accuracy: 0.9828\n",
      "Epoch 828/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0863 - accuracy: 0.9633 - val_loss: 0.0426 - val_accuracy: 0.9843\n",
      "Epoch 829/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0895 - accuracy: 0.9629 - val_loss: 0.0436 - val_accuracy: 0.9820\n",
      "Epoch 830/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0877 - accuracy: 0.9637 - val_loss: 0.0396 - val_accuracy: 0.9844\n",
      "Epoch 831/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0880 - accuracy: 0.9645 - val_loss: 0.0449 - val_accuracy: 0.9857\n",
      "Epoch 832/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0848 - accuracy: 0.9658 - val_loss: 0.0463 - val_accuracy: 0.9829\n",
      "Epoch 833/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.0868 - accuracy: 0.9653 - val_loss: 0.0431 - val_accuracy: 0.9853\n",
      "Epoch 834/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0886 - accuracy: 0.9647 - val_loss: 0.0425 - val_accuracy: 0.9837\n",
      "Epoch 835/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0908 - accuracy: 0.9635 - val_loss: 0.0431 - val_accuracy: 0.9845\n",
      "Epoch 836/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0947 - accuracy: 0.9641 - val_loss: 0.0439 - val_accuracy: 0.9863\n",
      "Epoch 837/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.0895 - accuracy: 0.9644 - val_loss: 0.0580 - val_accuracy: 0.9789\n",
      "Epoch 838/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.0870 - accuracy: 0.9635 - val_loss: 0.0440 - val_accuracy: 0.9817\n",
      "Epoch 839/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0899 - accuracy: 0.9635 - val_loss: 0.0530 - val_accuracy: 0.9852\n",
      "Epoch 840/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0908 - accuracy: 0.9625 - val_loss: 0.0573 - val_accuracy: 0.9776\n",
      "Epoch 841/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.0862 - accuracy: 0.9639 - val_loss: 0.0403 - val_accuracy: 0.9827\n",
      "Epoch 842/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0875 - accuracy: 0.9628 - val_loss: 0.0454 - val_accuracy: 0.9834\n",
      "Epoch 843/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0886 - accuracy: 0.9635 - val_loss: 0.0439 - val_accuracy: 0.9830\n",
      "Epoch 844/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0860 - accuracy: 0.9645 - val_loss: 0.0458 - val_accuracy: 0.9839\n",
      "Epoch 845/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0920 - accuracy: 0.9635 - val_loss: 0.0393 - val_accuracy: 0.9859\n",
      "Epoch 846/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0874 - accuracy: 0.9647 - val_loss: 0.0412 - val_accuracy: 0.9844\n",
      "Epoch 847/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0842 - accuracy: 0.9650 - val_loss: 0.0376 - val_accuracy: 0.9859\n",
      "Epoch 848/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0891 - accuracy: 0.9641 - val_loss: 0.0484 - val_accuracy: 0.9817\n",
      "Epoch 849/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0901 - accuracy: 0.9635 - val_loss: 0.0539 - val_accuracy: 0.9848\n",
      "Epoch 850/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0878 - accuracy: 0.9643 - val_loss: 0.0462 - val_accuracy: 0.9855\n",
      "Epoch 851/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0879 - accuracy: 0.9643 - val_loss: 0.0467 - val_accuracy: 0.9859\n",
      "Epoch 852/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0922 - accuracy: 0.9634 - val_loss: 0.0379 - val_accuracy: 0.9855\n",
      "Epoch 853/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0864 - accuracy: 0.9645 - val_loss: 0.0462 - val_accuracy: 0.9826\n",
      "Epoch 854/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0876 - accuracy: 0.9646 - val_loss: 0.0414 - val_accuracy: 0.9845\n",
      "Epoch 855/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0960 - accuracy: 0.9628 - val_loss: 0.0393 - val_accuracy: 0.9847\n",
      "Epoch 856/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0870 - accuracy: 0.9640 - val_loss: 0.0599 - val_accuracy: 0.9840\n",
      "Epoch 857/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0881 - accuracy: 0.9642 - val_loss: 0.0568 - val_accuracy: 0.9826\n",
      "Epoch 858/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0912 - accuracy: 0.9623 - val_loss: 0.0481 - val_accuracy: 0.9829\n",
      "Epoch 859/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0867 - accuracy: 0.9637 - val_loss: 0.0464 - val_accuracy: 0.9839\n",
      "Epoch 860/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0859 - accuracy: 0.9649 - val_loss: 0.0445 - val_accuracy: 0.9828\n",
      "Epoch 861/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0883 - accuracy: 0.9637 - val_loss: 0.0665 - val_accuracy: 0.9809\n",
      "Epoch 862/1000\n",
      "20631/20631 [==============================] - 1s 25us/sample - loss: 0.0910 - accuracy: 0.9646 - val_loss: 0.0469 - val_accuracy: 0.9830\n",
      "Epoch 863/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0859 - accuracy: 0.9643 - val_loss: 0.0421 - val_accuracy: 0.9859\n",
      "Epoch 864/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0902 - accuracy: 0.9621 - val_loss: 0.0424 - val_accuracy: 0.9856\n",
      "Epoch 865/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0886 - accuracy: 0.9631 - val_loss: 0.0450 - val_accuracy: 0.9858\n",
      "Epoch 866/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0877 - accuracy: 0.9628 - val_loss: 0.0403 - val_accuracy: 0.9840\n",
      "Epoch 867/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0883 - accuracy: 0.9638 - val_loss: 0.0428 - val_accuracy: 0.9840\n",
      "Epoch 868/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0866 - accuracy: 0.9636 - val_loss: 0.0563 - val_accuracy: 0.9835\n",
      "Epoch 869/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0885 - accuracy: 0.9625 - val_loss: 0.0424 - val_accuracy: 0.9861\n",
      "Epoch 870/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0886 - accuracy: 0.9644 - val_loss: 0.0476 - val_accuracy: 0.9802\n",
      "Epoch 871/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0881 - accuracy: 0.9650 - val_loss: 0.0410 - val_accuracy: 0.9843\n",
      "Epoch 872/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0873 - accuracy: 0.9648 - val_loss: 0.0427 - val_accuracy: 0.9840\n",
      "Epoch 873/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0891 - accuracy: 0.9632 - val_loss: 0.0368 - val_accuracy: 0.9868\n",
      "Epoch 874/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0885 - accuracy: 0.9632 - val_loss: 0.0401 - val_accuracy: 0.9832\n",
      "Epoch 875/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0883 - accuracy: 0.9643 - val_loss: 0.0404 - val_accuracy: 0.9849\n",
      "Epoch 876/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0858 - accuracy: 0.9648 - val_loss: 0.0392 - val_accuracy: 0.9853\n",
      "Epoch 877/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0890 - accuracy: 0.9652 - val_loss: 0.0401 - val_accuracy: 0.9842\n",
      "Epoch 878/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0938 - accuracy: 0.9629 - val_loss: 0.0654 - val_accuracy: 0.9783\n",
      "Epoch 879/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0876 - accuracy: 0.9633 - val_loss: 0.0443 - val_accuracy: 0.9824\n",
      "Epoch 880/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0882 - accuracy: 0.9635 - val_loss: 0.0420 - val_accuracy: 0.9848\n",
      "Epoch 881/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0863 - accuracy: 0.9644 - val_loss: 0.0686 - val_accuracy: 0.9807\n",
      "Epoch 882/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0890 - accuracy: 0.9636 - val_loss: 0.0453 - val_accuracy: 0.9839\n",
      "Epoch 883/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0871 - accuracy: 0.9648 - val_loss: 0.0462 - val_accuracy: 0.9818\n",
      "Epoch 884/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0895 - accuracy: 0.9640 - val_loss: 0.0445 - val_accuracy: 0.9839\n",
      "Epoch 885/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0901 - accuracy: 0.9632 - val_loss: 0.0374 - val_accuracy: 0.9856\n",
      "Epoch 886/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0866 - accuracy: 0.9638 - val_loss: 0.0489 - val_accuracy: 0.9832\n",
      "Epoch 887/1000\n",
      "20631/20631 [==============================] - 1s 28us/sample - loss: 0.0885 - accuracy: 0.9640 - val_loss: 0.0464 - val_accuracy: 0.9840\n",
      "Epoch 888/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0924 - accuracy: 0.9628 - val_loss: 0.0390 - val_accuracy: 0.9846\n",
      "Epoch 889/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0865 - accuracy: 0.9636 - val_loss: 0.0414 - val_accuracy: 0.9837\n",
      "Epoch 890/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0889 - accuracy: 0.9634 - val_loss: 0.0512 - val_accuracy: 0.9805\n",
      "Epoch 891/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0910 - accuracy: 0.9624 - val_loss: 0.0449 - val_accuracy: 0.9847\n",
      "Epoch 892/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0892 - accuracy: 0.9634 - val_loss: 0.0751 - val_accuracy: 0.9832\n",
      "Epoch 893/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0905 - accuracy: 0.9635 - val_loss: 0.0430 - val_accuracy: 0.9860\n",
      "Epoch 894/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0909 - accuracy: 0.9630 - val_loss: 0.0426 - val_accuracy: 0.9833\n",
      "Epoch 895/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0913 - accuracy: 0.9632 - val_loss: 0.0438 - val_accuracy: 0.9842\n",
      "Epoch 896/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0871 - accuracy: 0.9633 - val_loss: 0.0439 - val_accuracy: 0.9859\n",
      "Epoch 897/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0876 - accuracy: 0.9641 - val_loss: 0.0572 - val_accuracy: 0.9780\n",
      "Epoch 898/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0853 - accuracy: 0.9644 - val_loss: 0.0835 - val_accuracy: 0.9815\n",
      "Epoch 899/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0890 - accuracy: 0.9633 - val_loss: 0.0558 - val_accuracy: 0.9799\n",
      "Epoch 900/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0884 - accuracy: 0.9632 - val_loss: 0.0480 - val_accuracy: 0.9849\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0874 - accuracy: 0.9628 - val_loss: 0.0496 - val_accuracy: 0.9808\n",
      "Epoch 902/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0892 - accuracy: 0.9644 - val_loss: 0.0660 - val_accuracy: 0.9798\n",
      "Epoch 903/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9644 - val_loss: 0.0419 - val_accuracy: 0.9831\n",
      "Epoch 904/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0875 - accuracy: 0.9643 - val_loss: 0.0499 - val_accuracy: 0.9821\n",
      "Epoch 905/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0893 - accuracy: 0.9635 - val_loss: 0.0391 - val_accuracy: 0.9841\n",
      "Epoch 906/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0876 - accuracy: 0.9644 - val_loss: 0.0450 - val_accuracy: 0.9858\n",
      "Epoch 907/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0902 - accuracy: 0.9645 - val_loss: 0.0390 - val_accuracy: 0.9855\n",
      "Epoch 908/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0893 - accuracy: 0.9637 - val_loss: 0.0378 - val_accuracy: 0.9859\n",
      "Epoch 909/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0879 - accuracy: 0.9643 - val_loss: 0.0430 - val_accuracy: 0.9832\n",
      "Epoch 910/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0880 - accuracy: 0.9630 - val_loss: 0.0526 - val_accuracy: 0.9843\n",
      "Epoch 911/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0863 - accuracy: 0.9645 - val_loss: 0.0623 - val_accuracy: 0.9746\n",
      "Epoch 912/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0898 - accuracy: 0.9638 - val_loss: 0.0742 - val_accuracy: 0.9803\n",
      "Epoch 913/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0885 - accuracy: 0.9632 - val_loss: 0.0475 - val_accuracy: 0.9835\n",
      "Epoch 914/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0917 - accuracy: 0.9629 - val_loss: 0.0535 - val_accuracy: 0.9845\n",
      "Epoch 915/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0895 - accuracy: 0.9644 - val_loss: 0.0728 - val_accuracy: 0.9863\n",
      "Epoch 916/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0899 - accuracy: 0.9640 - val_loss: 0.0469 - val_accuracy: 0.9853\n",
      "Epoch 917/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0897 - accuracy: 0.9633 - val_loss: 0.0416 - val_accuracy: 0.9856\n",
      "Epoch 918/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0891 - accuracy: 0.9642 - val_loss: 0.0428 - val_accuracy: 0.9843\n",
      "Epoch 919/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0869 - accuracy: 0.9636 - val_loss: 0.0453 - val_accuracy: 0.9847\n",
      "Epoch 920/1000\n",
      "20631/20631 [==============================] - 0s 17us/sample - loss: 0.0870 - accuracy: 0.9645 - val_loss: 0.0402 - val_accuracy: 0.9853\n",
      "Epoch 921/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0891 - accuracy: 0.9616 - val_loss: 0.0707 - val_accuracy: 0.9819\n",
      "Epoch 922/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0914 - accuracy: 0.9629 - val_loss: 0.0439 - val_accuracy: 0.9830\n",
      "Epoch 923/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0871 - accuracy: 0.9632 - val_loss: 0.0411 - val_accuracy: 0.9859\n",
      "Epoch 924/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0870 - accuracy: 0.9637 - val_loss: 0.0486 - val_accuracy: 0.9863\n",
      "Epoch 925/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0943 - accuracy: 0.9639 - val_loss: 0.0529 - val_accuracy: 0.9854\n",
      "Epoch 926/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0907 - accuracy: 0.9634 - val_loss: 0.0503 - val_accuracy: 0.9805\n",
      "Epoch 927/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0862 - accuracy: 0.9648 - val_loss: 0.0396 - val_accuracy: 0.9852\n",
      "Epoch 928/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0879 - accuracy: 0.9630 - val_loss: 0.0785 - val_accuracy: 0.9801\n",
      "Epoch 929/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0908 - accuracy: 0.9625 - val_loss: 0.0384 - val_accuracy: 0.9852\n",
      "Epoch 930/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0882 - accuracy: 0.9627 - val_loss: 0.0364 - val_accuracy: 0.9861\n",
      "Epoch 931/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0875 - accuracy: 0.9635 - val_loss: 0.0524 - val_accuracy: 0.9795\n",
      "Epoch 932/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.0852 - accuracy: 0.9662 - val_loss: 0.0554 - val_accuracy: 0.9826\n",
      "Epoch 933/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.1074 - accuracy: 0.9629 - val_loss: 0.0471 - val_accuracy: 0.9855\n",
      "Epoch 934/1000\n",
      "20631/20631 [==============================] - 1s 26us/sample - loss: 0.0934 - accuracy: 0.9637 - val_loss: 0.0408 - val_accuracy: 0.9850\n",
      "Epoch 935/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0869 - accuracy: 0.9632 - val_loss: 0.0595 - val_accuracy: 0.9803\n",
      "Epoch 936/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0891 - accuracy: 0.9631 - val_loss: 0.0421 - val_accuracy: 0.9866\n",
      "Epoch 937/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.0882 - accuracy: 0.9646 - val_loss: 0.0484 - val_accuracy: 0.9819\n",
      "Epoch 938/1000\n",
      "20631/20631 [==============================] - 0s 23us/sample - loss: 0.0891 - accuracy: 0.9646 - val_loss: 0.0454 - val_accuracy: 0.9819\n",
      "Epoch 939/1000\n",
      "20631/20631 [==============================] - 0s 22us/sample - loss: 0.0865 - accuracy: 0.9642 - val_loss: 0.0430 - val_accuracy: 0.9830\n",
      "Epoch 940/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0858 - accuracy: 0.9632 - val_loss: 0.0430 - val_accuracy: 0.9822\n",
      "Epoch 941/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0908 - accuracy: 0.9640 - val_loss: 0.0413 - val_accuracy: 0.9843\n",
      "Epoch 942/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0884 - accuracy: 0.9633 - val_loss: 0.0559 - val_accuracy: 0.9826\n",
      "Epoch 943/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0886 - accuracy: 0.9637 - val_loss: 0.0628 - val_accuracy: 0.9762\n",
      "Epoch 944/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0883 - accuracy: 0.9639 - val_loss: 0.0644 - val_accuracy: 0.9819\n",
      "Epoch 945/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0881 - accuracy: 0.9636 - val_loss: 0.0608 - val_accuracy: 0.9807\n",
      "Epoch 946/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0884 - accuracy: 0.9642 - val_loss: 0.0400 - val_accuracy: 0.9860\n",
      "Epoch 947/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0888 - accuracy: 0.9639 - val_loss: 0.0484 - val_accuracy: 0.9821\n",
      "Epoch 948/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0927 - accuracy: 0.9651 - val_loss: 0.0491 - val_accuracy: 0.9824\n",
      "Epoch 949/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0906 - accuracy: 0.9628 - val_loss: 0.0474 - val_accuracy: 0.9824\n",
      "Epoch 950/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0892 - accuracy: 0.9644 - val_loss: 0.0457 - val_accuracy: 0.9830\n",
      "Epoch 951/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0904 - accuracy: 0.9632 - val_loss: 0.0431 - val_accuracy: 0.9834\n",
      "Epoch 952/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0898 - accuracy: 0.9648 - val_loss: 0.0398 - val_accuracy: 0.9846\n",
      "Epoch 953/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0891 - accuracy: 0.9628 - val_loss: 0.0380 - val_accuracy: 0.9843\n",
      "Epoch 954/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0860 - accuracy: 0.9639 - val_loss: 0.0421 - val_accuracy: 0.9842\n",
      "Epoch 955/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0903 - accuracy: 0.9646 - val_loss: 0.0513 - val_accuracy: 0.9837\n",
      "Epoch 956/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0891 - accuracy: 0.9639 - val_loss: 0.0427 - val_accuracy: 0.9828\n",
      "Epoch 957/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0868 - accuracy: 0.9641 - val_loss: 0.0468 - val_accuracy: 0.9851\n",
      "Epoch 958/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0902 - accuracy: 0.9630 - val_loss: 0.0401 - val_accuracy: 0.9850\n",
      "Epoch 959/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0883 - accuracy: 0.9642 - val_loss: 0.0417 - val_accuracy: 0.9842\n",
      "Epoch 960/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0875 - accuracy: 0.9636 - val_loss: 0.0370 - val_accuracy: 0.9863\n",
      "Epoch 961/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0870 - accuracy: 0.9641 - val_loss: 0.0399 - val_accuracy: 0.9863\n",
      "Epoch 962/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0861 - accuracy: 0.9624 - val_loss: 0.0539 - val_accuracy: 0.9808\n",
      "Epoch 963/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0860 - accuracy: 0.9648 - val_loss: 0.0525 - val_accuracy: 0.9812\n",
      "Epoch 964/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0890 - accuracy: 0.9649 - val_loss: 0.0455 - val_accuracy: 0.9830\n",
      "Epoch 965/1000\n",
      "20631/20631 [==============================] - 0s 18us/sample - loss: 0.0864 - accuracy: 0.9651 - val_loss: 0.0540 - val_accuracy: 0.9855\n",
      "Epoch 966/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0885 - accuracy: 0.9638 - val_loss: 0.0429 - val_accuracy: 0.9836\n",
      "Epoch 967/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0847 - accuracy: 0.9635 - val_loss: 0.0452 - val_accuracy: 0.9818\n",
      "Epoch 968/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.1002 - accuracy: 0.9637 - val_loss: 0.0477 - val_accuracy: 0.9830\n",
      "Epoch 969/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0896 - accuracy: 0.9627 - val_loss: 0.0546 - val_accuracy: 0.9800\n",
      "Epoch 970/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0906 - accuracy: 0.9636 - val_loss: 0.0608 - val_accuracy: 0.9811\n",
      "Epoch 971/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0883 - accuracy: 0.9629 - val_loss: 0.0415 - val_accuracy: 0.9853\n",
      "Epoch 972/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0875 - accuracy: 0.9644 - val_loss: 0.1269 - val_accuracy: 0.9814\n",
      "Epoch 973/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0899 - accuracy: 0.9643 - val_loss: 0.0482 - val_accuracy: 0.9837\n",
      "Epoch 974/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0888 - accuracy: 0.9618 - val_loss: 0.0446 - val_accuracy: 0.9850\n",
      "Epoch 975/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0886 - accuracy: 0.9629 - val_loss: 0.0616 - val_accuracy: 0.9821\n",
      "Epoch 976/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0902 - accuracy: 0.9635 - val_loss: 0.0446 - val_accuracy: 0.9835\n",
      "Epoch 977/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0876 - accuracy: 0.9647 - val_loss: 0.0409 - val_accuracy: 0.9851\n",
      "Epoch 978/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0874 - accuracy: 0.9648 - val_loss: 0.0383 - val_accuracy: 0.9853\n",
      "Epoch 979/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0861 - accuracy: 0.9636 - val_loss: 0.0455 - val_accuracy: 0.9831\n",
      "Epoch 980/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0897 - accuracy: 0.9628 - val_loss: 0.0533 - val_accuracy: 0.9822\n",
      "Epoch 981/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0883 - accuracy: 0.9646 - val_loss: 0.0439 - val_accuracy: 0.9839\n",
      "Epoch 982/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0882 - accuracy: 0.9646 - val_loss: 0.0437 - val_accuracy: 0.9845\n",
      "Epoch 983/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0880 - accuracy: 0.9632 - val_loss: 0.0454 - val_accuracy: 0.9843\n",
      "Epoch 984/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0925 - accuracy: 0.9638 - val_loss: 0.0425 - val_accuracy: 0.9840\n",
      "Epoch 985/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0877 - accuracy: 0.9646 - val_loss: 0.0378 - val_accuracy: 0.9850\n",
      "Epoch 986/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0873 - accuracy: 0.9641 - val_loss: 0.0542 - val_accuracy: 0.9848\n",
      "Epoch 987/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0885 - accuracy: 0.9630 - val_loss: 0.0407 - val_accuracy: 0.9841\n",
      "Epoch 988/1000\n",
      "20631/20631 [==============================] - 0s 21us/sample - loss: 0.0866 - accuracy: 0.9650 - val_loss: 0.0578 - val_accuracy: 0.9818\n",
      "Epoch 989/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0862 - accuracy: 0.9653 - val_loss: 0.0460 - val_accuracy: 0.9834\n",
      "Epoch 990/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0868 - accuracy: 0.9633 - val_loss: 0.0436 - val_accuracy: 0.9839\n",
      "Epoch 991/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0861 - accuracy: 0.9662 - val_loss: 0.0644 - val_accuracy: 0.9810\n",
      "Epoch 992/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0855 - accuracy: 0.9648 - val_loss: 0.0365 - val_accuracy: 0.9870\n",
      "Epoch 993/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0875 - accuracy: 0.9647 - val_loss: 0.0418 - val_accuracy: 0.9832\n",
      "Epoch 994/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0858 - accuracy: 0.9643 - val_loss: 0.0463 - val_accuracy: 0.9824\n",
      "Epoch 995/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0898 - accuracy: 0.9640 - val_loss: 0.0457 - val_accuracy: 0.9823\n",
      "Epoch 996/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0940 - accuracy: 0.9633 - val_loss: 0.0384 - val_accuracy: 0.9854\n",
      "Epoch 997/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0858 - accuracy: 0.9649 - val_loss: 0.0639 - val_accuracy: 0.9798\n",
      "Epoch 998/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0842 - accuracy: 0.9646 - val_loss: 0.0384 - val_accuracy: 0.9851\n",
      "Epoch 999/1000\n",
      "20631/20631 [==============================] - 0s 19us/sample - loss: 0.0869 - accuracy: 0.9645 - val_loss: 0.0471 - val_accuracy: 0.9807\n",
      "Epoch 1000/1000\n",
      "20631/20631 [==============================] - 0s 20us/sample - loss: 0.0881 - accuracy: 0.9644 - val_loss: 0.0556 - val_accuracy: 0.9811\n"
     ]
    }
   ],
   "source": [
    "test = model.fit(x_train,y_train, batch_size =128,epochs = 1000, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred=ypred>0.9\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9854917532070862"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ypred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12701,    63],\n",
       "       [  127,   205]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm1 = confusion_matrix(y_test,ypred)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Engine_maintenance_keras.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save(\"test1.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
